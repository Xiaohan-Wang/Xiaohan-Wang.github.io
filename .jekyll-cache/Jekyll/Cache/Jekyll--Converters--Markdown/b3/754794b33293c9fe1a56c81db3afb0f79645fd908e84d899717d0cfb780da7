I"Ã<p><a href="https://arxiv.org/pdf/1902.06162.pdf">Paper link</a></p>

<h4 id="self-supervised-feature-learning">self-supervised feature learning</h4>
<ul>
  <li>learn visual features from large-scale unlabeled images or videos without using any human annotations</li>
  <li>a subset of unsupervised learning methods</li>
  <li>pretext task: the supervisory signal is generated from the data itself by leveraging its structure</li>
  <li>visual features of images or videos need to be captured by ConvNets to solve the pretext tasks</li>
</ul>

<h4 id="ä½œç”¨">ä½œç”¨</h4>
<ol>
  <li>ä½œä¸ºpretext taskè·å¾—pre-trained model
    <ul>
      <li>æä¾›ä¸€ä¸ªå¥½çš„èµ·å§‹ç‚¹ï¼ŒåŠ é€Ÿæ”¶æ•›</li>
      <li>å·²ç»å­¦ä¹ åˆ°hierarchy featuresï¼Œå³ä½¿downstream taskçš„æ•°æ®é›†å¾ˆå°ï¼Œä¹Ÿä¸ä¼šè¿‡æ‹Ÿåˆå¤ªä¸¥é‡</li>
    </ul>
  </li>
  <li>ä½œä¸ºauxiliary taskæ¥æ·»åŠ regularization</li>
</ol>

<h4 id="åˆ†ç±»">åˆ†ç±»</h4>
<p><img src="/img/15932024508723.jpg" alt="-w1112" /></p>
<ol>
  <li>Information recovery: å…ˆæŠ¹é™¤å›¾ç‰‡çš„ä¸€éƒ¨åˆ†ä¿¡æ¯ï¼Œç„¶åè®©ç½‘ç»œå­¦ä¹ æ¢å¤è¿™äº›ä¿¡æ¯
    <ul>
      <li>generation based:
        <ul>
          <li><strong>image generation</strong>: help the network to capture the real distribution of the real data and generate realists data</li>
          <li><strong>color recovery</strong>: network need to recognize objects and to group pixels of the same part together</li>
          <li><strong>inpainting</strong>: networks are required to learn the common knowledge including the color and structure of the common objects</li>
          <li><strong>super resolution</strong>: learn the semantic features of images</li>
        </ul>
      </li>
      <li>context based:
        <ul>
          <li><strong>Context Similarity (contrasting)</strong>: learn the invariance within one class and the variance among different classes
            <ul>
              <li>contrasting: train networks to maximum agreement of different views of same scene while minimizing agreement of views from different scenes</li>
            </ul>
          </li>
          <li><strong>Spatial Context Structure</strong>ï¼šlearn spatial context information such as the shape of the objects and the relative positions of different parts of an object</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Hard-code program
    <ul>
      <li>This type of methods generally has two steps: (1) label generation by employing hard-code programs on images or videos to obtain labels, (2) train ConvNets with the generated labels.</li>
      <li>distill knowledge from hard-code detector</li>
      <li>one drawback is that the semantic labels generated by hard-code detector usually are very noisy which need to specifically cope with.
    * Game Engines</li>
      <li>game engines are able to render realistic images and provide accurate pixel-level labels</li>
      <li>one problem is the domain gap between synthetic and real-world images</li>
    </ul>
  </li>
</ol>

<h4 id="performance">Performance</h4>
<p><img src="/img/15932060535480.jpg" alt="-w913" />
The performance of self-supervised methods are comparable to the supervised methods on some downstream tasks, especially for the object detection and semantic segmentation tasks.</p>

:ET