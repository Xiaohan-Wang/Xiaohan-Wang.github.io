I"S
<h4 id="warm-up">Warm up</h4>

<h4 id="learning-rate-decay">Learning rate decay</h4>
<p>å­¦ä¹ ç‡è¡°å‡çš„åŸºæœ¬æ€æƒ³æ˜¯å­¦ä¹ ç‡éšç€è®­ç»ƒçš„è¿›è¡Œé€æ¸è¡°å‡ï¼Œå³åœ¨å¼€å§‹çš„æ—¶å€™ä½¿ç”¨è¾ƒå¤§çš„å­¦ä¹ ç‡ï¼ŒåŠ å¿«é è¿‘æœ€å°å€¼çš„é€Ÿåº¦ï¼Œåœ¨åæ¥äº›æ—¶å€™ç”¨è¾ƒå°çš„å­¦ä¹ ç‡ï¼Œæé«˜ç¨³å®šæ€§ï¼Œé¿å…å› å­¦ä¹ ç‡å¤ªå¤§è·³è¿‡æœ€å°å€¼ï¼Œä¿è¯èƒ½å¤Ÿæ”¶æ•›åˆ°æœ€å°å€¼ã€‚</p>

<ol>
  <li>
    <p>step(å›ºå®šæ­¥é•¿è¡°å‡): æ¯éš”step_sizeä¸ªepochåï¼Œlrè¡°å‡ä¸ºåŸæ¥çš„gammaå€</p>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="c1"># pytorch
</span>    
 <span class="n">CLASS</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">StepLR</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">step_size</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">last_epoch</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div>    </div>

    <p><img src="/img/15906775729941.jpg" width="50%" height="100%" /></p>
  </li>
  <li>
    <p>multistep(å¤šæ­¥é•¿è¡°å‡): åŠ¨æ€æ­¥é•¿æ§åˆ¶ï¼Œlrè¡°å‡ä¸ºåŸæ¥çš„gammaå€</p>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="c1"># pytorch
</span>    
  <span class="n">CLASS</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">MultiStepLR</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">milestones</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">last_epoch</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div>    </div>

    <p><img src="/img/15906776874073.jpg" width="50%" height="100%" /></p>
  </li>
  <li>
    <p>poly(å¤šé¡¹å¼è¡°å‡): $lr = \text{base_lr} * (1 - \frac{T_{cur}}{T_{max}}) ^ {power} $
 <img src="/img/15906784236558.jpg" width="50%" height="100%" />
 å­¦ä¹ ç‡æ›²çº¿çš„å½¢çŠ¶ä¸»è¦ç”±å‚æ•° power çš„å€¼æ¥æ§åˆ¶ã€‚å½“ power = 1 çš„æ—¶å€™ï¼Œå­¦ä¹ ç‡æ›²çº¿ä¸ºä¸€æ¡ç›´çº¿ã€‚å½“ power &lt; 1 çš„æ—¶å€™ï¼Œä¸‹é™é€Ÿç‡ç”±æ…¢åˆ°å¿«ã€‚å½“ power &gt; 1 çš„æ—¶å€™ï¼Œä¸‹é™é€Ÿç‡ç”±å¿«åˆ°æ…¢ã€‚</p>
  </li>
  <li>
    <p>cosine(ä½™å¼¦è¡°å‡): $lr = \frac{1}{2}*\text{base_lr} * \left(1+ \cos\left(\frac{T_{cur}}{T_{max}}\pi\right)\right)$</p>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="c1">#pytorch
</span>    
 <span class="n">CLASS</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">CosineAnnealingLR</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">T_max</span><span class="p">,</span> <span class="n">eta_min</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">last_epoch</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div>    </div>
    <p><img src="/img/15906782692333.jpg" width="50%" height="100%" />
 ä½™å¼¦å€¼é¦–å…ˆç¼“æ…¢ä¸‹é™ï¼Œç„¶ååŠ é€Ÿä¸‹é™ï¼Œä¹‹åå†æ¬¡ç¼“æ…¢ä¸‹é™ã€‚</p>
  </li>
</ol>

<h4 id="å‚è€ƒèµ„æ–™">å‚è€ƒèµ„æ–™</h4>
<ol>
  <li>https://lumingdong.cn/setting-strategy-of-gradient-descent-learning-rate.html</li>
  <li>https://zhuanlan.zhihu.com/p/39565465</li>
</ol>

:ET