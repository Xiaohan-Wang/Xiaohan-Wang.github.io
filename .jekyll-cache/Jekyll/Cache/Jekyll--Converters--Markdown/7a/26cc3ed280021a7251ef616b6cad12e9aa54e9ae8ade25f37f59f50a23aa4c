I"Ñ	<p><a href="https://www.aaai.org/Papers/AAAI/2007/AAAI07-262.pdf">AAAI 2007 paper</a> and <a href="http://www.jmlr.org/papers/volume13/gretton12a/gretton12a.pdf">JMLR 2012 paper</a></p>

<h4 id="mmdä½œç”¨">MMDä½œç”¨</h4>
<ul>
  <li>ä¼ ç»Ÿçš„ç”¨äºè¡¡é‡ä¸¤ä¸ªæ¦‚ç‡åˆ†å¸ƒPå’ŒQå·®åˆ«çš„æ–¹æ³•ï¼Œä¾‹å¦‚KL divergenceï¼Œè¦æ±‚æ¦‚ç‡åˆ†å¸ƒPå’ŒQå·²çŸ¥ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œ<strong>å¦‚æœæˆ‘ä»¬åªæœ‰æ¥è‡ªPå’ŒQçš„æ ·æœ¬ï¼Œé‚£ä¹ˆæˆ‘ä»¬éœ€è¦å…ˆè¿›è¡Œæ¦‚ç‡å¯†åº¦ä¼°è®¡ (density estimation)ï¼Œç„¶åæ‰èƒ½è¡¡é‡ä¸¤ä¸ªåˆ†å¸ƒçš„å·®å¼‚</strong>ã€‚</li>
  <li>MMDï¼šåˆ©ç”¨æ¥è‡ªPå’ŒQçš„æ ·æœ¬ï¼Œç›´æ¥è·å¾—å®ƒä»¬å¯¹åº”çš„æ€»ä½“æ¦‚ç‡åˆ†å¸ƒçš„å·®å¼‚ï¼Œè€Œæ— éœ€density estimationè¿™ä¸€ä¸­é—´æ­¥éª¤ã€‚</li>
</ul>

<h4 id="mmdè®¡ç®—">MMDè®¡ç®—</h4>
<ul>
  <li>Give observations $X := {x_1, \cdots , x_m}$ and $Y := {y_1, \cdots, y_n}$, which are independently and identically distributed (i.i.d.) from distribution $p$ and $q$. Let $\mathcal{F}$ be a class of functions $f : X \to \mathbb{R}$, and shorthand notation $E_x[ f(x)] :=E_{x \sim p}[ f(x)]$ and $E_y[ f(y)] := E_{y\sim q}[ f(y)]$ denote expectations with respect to $p$ and $q$, respectively, where $x \sim p$ indicates x has distribution $p$.</li>
  <li>
    <p>Maximum mean discrepancy (MMD) is defined as:</p>

    <script type="math/tex; mode=display">MMD[\mathcal{F}, p,q] := \sup_{f \in \mathcal{F}}(E_x[ f(x)]âˆ’E_y[ f(y)]) .</script>

    <p>We must therefore dentify a function class that is <strong>rich enough to uniquely identify whether $p = q$</strong>. And since we want to obtain this discrepancy by sample $X$ and $Y$,  the function class should also be <strong>restrictive enough to provide useful finite sample estimates</strong>.</p>
  </li>
  <li>
    <p>Propose the unit ball in a reproducing kernel Hilbert space $\mathcal H$ as our MMD function class $\mathcal{F}$. Define $\mu_p(t) \in \mathcal{H}$ such that <script type="math/tex">E_x [f(x)] = \lt f, \mu_p \gt _{\mathcal{H}}</script> for all $f \in \mathcal{H}$. If we set $f= \phi (t) = k(t, \cdot)$, we obtain $\mu_p(t) = &lt;\mu_p, k(t, Â·)&gt;_\mathcal{H} =E_xk(t, x)$, in other words, the mean embedding of the distribution $p$ is the expectation under $p$ of the canonical feature map.</p>

    <script type="math/tex; mode=display">% <![CDATA[
MMD^2 \left[ \mathcal{F}, p,q \right] = \left[ \sup_{||f||_\mathcal{H} \leq 1}(E_x [ f(x)]âˆ’E_y [ f(y)])
\right]^2\\=    \left[ \sup_{||f||_\mathcal{H} \leq 1}<\mu_p-\mu_q,f>_\mathcal{H}
\right]^2\\ %]]></script>
  </li>
  <li></li>
</ul>

:ET