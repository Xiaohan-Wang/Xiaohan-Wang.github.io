I"K<h4 id="核方法kernel-method">核方法（kernel method）</h4>
<ul>
  <li>理论基础: Cover’s theorem，其指出，在低维空间中线性不可分的数据，通过非线性变换将其投影到高维空间之后，大概率会变为线性可分的数据</li>
  <li><strong>将低维空间的非线性可分问题，转化为高维空间的线性可分问题</strong></li>
</ul>

<h4 id="核技巧kernel-trick">核技巧（kernel trick）</h4>
<p>设$\phi(x)$为映射函数，$\phi(x): \mathcal{X} \to \mathcal{H}$，其中$\mathcal{X}$为输入空间，$\mathcal{H}$为特征空间 (特征空间需要是Hilbert space，即完备的内积空间)。</p>

<p>欲求$&lt;\phi(x_1), \phi(x_2)&gt;$：</p>
<ul>
  <li>传统方法：先分别计算$\phi(x_1)$和$\phi(x_2)$，再在特征空间中计算二者的内积
    <ul>
      <li>缺点：当特征空间维度很大时，计算非常复杂</li>
    </ul>
  </li>
  <li>核技巧：在输入空间找到一个函数$K(x_1, x_2)$，使得$K(x_1, x_2)=&lt;\phi(x_1), \phi(x_2)&gt;$，从而可以直接在低维空间中计算出结果，加速核方法计算。对应的函数 $K$ 就是核函数</li>
</ul>

<h4 id="核函数kernels">核函数（kernels）</h4>
<ul>
  <li>在实际应用时，映射函数 $\phi(x)$ 不需要是已知的。换句话说，核技巧的目的就是在不需要知道具体映射函数的条件下，计算映射之后的内积</li>
  <li>核函数 $K$ 本质上需要满足的条件 (不需要$\phi(x)$已知):
    <ul>
      <li>对称性: $K(\mathrm{x_1},\mathrm{x_2}) = K(\mathrm{x_2},\mathrm{x_1})$</li>
      <li>半正定性: 对于任意 $n$ 和任意 $x_1, x_2, \cdots, x_n  \in \mathcal{X}$，由 $K(x_i, x_j)$ 定义的 Gram matrix 总是半正定的</li>
    </ul>
  </li>
  <li>只要 $K$ 是核函数，那么一定存在一个Hilbert space和一个映射函数$\phi$，使得$K(x_1, x_2)=&lt;\phi(x_1), \phi(x_2)&gt;$</li>
  <li>常见核函数<br />
  <img src="/img/15923213053700.jpg" width="90%" height="100%" /><br />
  其它变换得到的核函数：参考资料3 $\text{P}_{17, 18}$</li>
</ul>

<h4 id="再生核希尔伯特空间reproducing-kernel-hilbert-spacesrkhs">再生核希尔伯特空间（reproducing kernel Hilbert spaces，RKHS）</h4>
<ul>
  <li>RKHS是一个函数空间，其中的元素 $f$ 为函数。通常情况下特征空间 $\mathcal{H}$ 为 RKHS。</li>
  <li>再生核 $K$ 是核函数的一种，其满足
    <ul>
      <li>对于任意固定的 $x_0\in\mathcal{X}$，$K(x,x_0)$作为 $x$ 的函数属于我们的函数空间$\mathcal{H}$</li>
      <li>对于任意 $x\in\mathcal{X}$ 和 $f(\cdot)\in\mathcal{H}$，有$f(x) = \langle f(\cdot),K(\cdot,x)\rangle$ (再生性质 / reproducing property)</li>
    </ul>
  </li>
  <li>
    <p>对于再生核 $K$，我们可以自然的定义映射函数 $\phi(x)=K(\cdot, x)$，此时，通过再生核的再生性质，可知
<script type="math/tex">\langle \phi(x_1),\phi(x_2)\rangle = \langle K(\cdot,x_1),K(\cdot,x_2)\rangle = K(x_1,x_2)</script></p>
  </li>
  <li>不是所有的Hilbert space都具有reproducing kernel</li>
  <li></li>
  <li></li>
  <li>对于任意一个核函数 $K$，都存在多个对应的特征空间0，在这之中，RKHS是最为“精简”的一个，这里的精简体现在无论在0中得到怎样的分类模型⟨w,ϕ0(x)⟩0，在RKHS中都存在一个f可以得到和它相同的效果，因此对于某个核函数，RKHS代表了它最本征的信息</li>
</ul>

<h4 id="参考资料">参考资料</h4>
<ol>
  <li>https://zhuanlan.zhihu.com/p/61794781</li>
  <li>http://www.fanyeong.com/2017/11/13/the-kernel-trick/</li>
  <li><a href="https://www.stat.berkeley.edu/~bartlett/courses/2014spring-cs281bstat241b/lectures/20-notes.pdf">CS281B/Stat241B. Statistical Learning Theory. Lecture
20.</a></li>
  <li>https://cosx.org/2014/05/svm-series-add-2-kernel-ii/</li>
</ol>
:ET