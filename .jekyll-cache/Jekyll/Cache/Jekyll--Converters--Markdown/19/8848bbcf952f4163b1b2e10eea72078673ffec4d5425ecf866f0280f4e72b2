I"£<p>éƒ¨åˆ†å†…å®¹æ¥è‡ªäº https://blog.csdn.net/MOU_IT/article/details/82225505</p>

<h4 id="æ€»è¿°">æ€»è¿°</h4>
<p>ç›®å‰å­¦æœ¯ç•Œä¸»è¦æœ‰ä¸‰ä¸ªbenchmarkï¼ˆæ•°æ®é›†ï¼‰ç”¨äºæ¨¡å‹è®­ç»ƒå’Œæµ‹è¯•ã€‚</p>
<ol>
  <li>Pascal VOCç³»åˆ—
    <ul>
      <li>VOC 2012 (æœ€å¸¸è§)</li>
      <li>Pascal Context (å¶å°”)</li>
    </ul>
  </li>
  <li>
    <p>Microsoft COCO<br />
 COCOä¸€å…±æœ‰80ä¸ªç±»åˆ«ã€‚è™½ç„¶æœ‰å¾ˆè¯¦ç»†çš„åƒç´ çº§åˆ«çš„æ ‡æ³¨ï¼Œä½†ç”±äºå®˜æ–¹æ²¡æœ‰ä¸“é—¨å¯¹è¯­ä¹‰åˆ†å‰²çš„æµ‹è¯„ï¼Œå› æ­¤COCOæ•°æ®é›†å¾€å¾€è¢«å½“æˆæ˜¯é¢å¤–çš„è®­ç»ƒæ•°æ®é›†ç”¨äºæ¨¡å‹çš„è®­ç»ƒï¼ˆé¢„è®­ç»ƒï¼Ÿï¼‰ã€‚</p>
  </li>
  <li>Cityscapes
    <ul>
      <li>è¾…åŠ©é©¾é©¶ï¼ˆè‡ªåŠ¨é©¾é©¶ï¼‰ç¯å¢ƒ</li>
      <li>ä½¿ç”¨æ¯”è¾ƒå¸¸è§çš„19ä¸ªç±»åˆ«ç”¨äºè¯„æµ‹</li>
    </ul>
  </li>
</ol>

<h4 id="voc-2012">VOC 2012</h4>

<p>æ ‡å‡†çš„VOC2012æ•°æ®é›†æœ‰21ä¸ªç±»åˆ«(åŒ…æ‹¬èƒŒæ™¯)ï¼ŒåŒ…å«:{Â 0=backgroundï¼Œ1=aeroplane, 2=bicycle, 3=bird, 4=boat, 5=bottle, 6=bus, 7=car , 8=cat, 9=chair, 10=cow, 11=diningtable, 12=dog, 13=horse, 14=motorbike, 15=person, 16=potted plant, 17=sheep, 18=sofa, 19=train, 20=tv/monitorï¼Œ255=Â â€™voidâ€™ or unlabelled }è¿™äº›æ¯”è¾ƒå¸¸è§çš„ç±»åˆ«ã€‚</p>

<p>å¯¹äºåˆ†å‰²ä»»åŠ¡ï¼š</p>
<ol>
  <li>VOC 2012ç”¨äºåˆ†å‰²çš„æ•°æ®ä¸­train+valåŒ…å« 2007-2011å¹´é—´çš„æ‰€æœ‰æ•°æ®ï¼ŒteståŒ…å«2008-2011å¹´é—´çš„æ•°æ®ï¼Œæ²¡æœ‰åŒ…å«07å¹´çš„æ˜¯å› ä¸º07å¹´çš„testæ•°æ®å·²ç»å…¬å¼€äº†ã€‚</li>
  <li>trainvalï¼š2913å¼ å›¾ç‰‡ï¼Œå…±6929ä¸ªç‰©ä½“</li>
</ol>

<p>è¡¥å……ï¼š<a href="https://arleyzhang.github.io/articles/1dc20586/">PASCAL VOCè¯¦ç»†ä»‹ç»</a></p>

<h4 id="ms-coco">MS COCO</h4>
<ol>
  <li>å®˜æ–¹æ²¡æœ‰semantic segmentationæµ‹è¯„ï¼Œå› æ­¤è¯¥æ•°æ®é›†å¸¸å¸¸åªç”¨äºé¢„è®­ç»ƒ</li>
  <li>æ•°æ®é›†å¤§å°ï¼Ÿ</li>
</ol>

<h4 id="cityscapes">Cityscapes</h4>

<p>è¡¥å……: <a href="https://niecongchong.github.io/2019/08/10/CityScapes%E6%95%B0%E6%8D%AE%E9%9B%86%E7%AE%80%E4%BB%8B%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E5%92%8C%E7%B2%BE%E5%BA%A6%E6%8C%87%E6%A0%87/">Cityscapesè¯¦ç»†ä»‹ç»</a></p>

<ol>
  <li>åŒ…å«æ¥è‡ª50ä¸ªä¸åŒåŸå¸‚çš„è¡—é“åœºæ™¯ï¼ˆä¸»è¦åœ¨å¾·å›½ï¼‰</li>
  <li>ä»27ä¸ªåŸå¸‚ä¸­é€‰æ‹©äº†5000å¼ å›¾åƒè¿›è¡Œdense pixel-level annotationï¼Œå…¶ä½™23ä¸ªåŸå¸‚æä¾›äº†20000å¼ æœ‰coarse annotationçš„å›¾åƒ</li>
  <li>annotationåŒ…æ‹¬
    <ul>
      <li>pixel-level annotation</li>
      <li>instance-level labels for humans and vehicles</li>
    </ul>
  </li>
  <li>å®šä¹‰äº†8ä¸ªå¤§ç±»(category)ï¼Œä¸‹åˆ†ä¸º30ä¸ªå°ç±»(class)
    <ul>
      <li>voidä»£è¡¨unclear (voidç±»ä¼šåœ¨trainingå’Œevaluationè¿‡ç¨‹ä¸­è¢«å¿½ç•¥)</li>
      <li>evaluationè¿‡ç¨‹ä¸­ï¼Œä¼šå¿½ç•¥å¤ªä¸å¸¸è§çš„classesï¼Œå³å‰©ä½™19ä¸ªclasses
 <img src="/img/15875266001958.jpg" alt="-w721" /></li>
    </ul>
  </li>
  <li>densely annotated imagesè¢«åˆ†ä¸ºtraining, validationå’Œtest sets, è€Œcoarsely annotated images åªä½œä¸ºé¢å¤–çš„training data
    <ul>
      <li>a city is completely within a single split</li>
      <li>densely annotated imagesä¸­ï¼š2975 training, 500 validation images, and 1525 test images</li>
      <li>æ¯å¼ å›¾ç‰‡å¤§å°éƒ½æ˜¯1024x2048
 <img src="/img/15903541919594.jpg" alt="-w878" /></li>
    </ul>
  </li>
  <li>è¯„ä»·æŒ‡æ ‡ï¼š
     * Pixel-Level Semantic Labelling
         * $IoU_{category}å’ŒIoU_{class}$
         * $iIoU_{category}å’ŒiIoU_{class}$ (instance-level intersection-over-union metric)
             * In contrast to the standard IoU measure, the contribution of each pixel is weighted by the ratio of the classâ€™ average instance size to the size of the respective ground truth instance.
             * $iIoU$ metric treats instances of any size equally and is therefore more sensitive to errors in predicting small objects compared to the $IoU$
     * Instance-Level Semantic Labeling</li>
</ol>

:ET