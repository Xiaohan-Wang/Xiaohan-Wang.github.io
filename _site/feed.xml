<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Xiaohan's Blog</title>
    <description>Do it now.</description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Wed, 08 Jul 2020 10:45:48 -0400</pubDate>
    <lastBuildDate>Wed, 08 Jul 2020 10:45:48 -0400</lastBuildDate>
    <generator>Jekyll v4.0.0</generator>
    
      <item>
        <title>Context Encoders:_Feature Learning by Inpainting</title>
        <description>&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1604.07379.pdf&quot;&gt;Paper link&lt;/a&gt; and &lt;a href=&quot;http://people.eecs.berkeley.edu/~pathak/context_encoder/&quot;&gt;website&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&quot;take-away-message&quot;&gt;Take away message&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;Image inpainting:
    &lt;ul&gt;
      &lt;li&gt;to fill in large missing areas of the image, it can’t get “hints” from nearby pixels&lt;/li&gt;
      &lt;li&gt;a model needs to both understand the content of an image, as well as produce a plausible hypothesis for the missing parts&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;a standard pixel-wise reconstruction loss&lt;/strong&gt;: only the reconstruction loss produces blurry results&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;an adversarial loss&lt;/strong&gt;: adding the adversarial loss results in much sharper predictions&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;model&quot;&gt;Model&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;Encoder-decoder pipeline:
    &lt;ul&gt;
      &lt;li&gt;encoder: produces a latent feature representation of that image&lt;/li&gt;
      &lt;li&gt;decoder: takes this feature representation and produces the missing image content
        &lt;ul&gt;
          &lt;li&gt;a series of five up-convolutional layers (upsampling followed by convolution)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;channel-wise fully-connected layer&lt;/strong&gt;: connect the encoder and the decoder
        &lt;ul&gt;
          &lt;li&gt;directly propagate information from one corner of the feature map to another corner (so that we can better capture global semantic information)&lt;/li&gt;
          &lt;li&gt;essentially a fully-connected layer with groups: only propagates information within feature maps, but it has no parameters connecting different feature maps&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Loss function:
    &lt;ul&gt;
      &lt;li&gt;reconstruction (L2) loss: 
  &lt;img src=&quot;/img/15942152334674.jpg&quot; width=&quot;50%&quot; height=&quot;100%&quot; /&gt;
        &lt;ul&gt;
          &lt;li&gt;capturing the overall structure of the missing region and coherence with regards to its context, but prefer a blurry solution (because the expectation of all possible values minimizes the mean squared pixel-wise error)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;adversarial loss: 
  &lt;img src=&quot;/img/15942164552075.jpg&quot; width=&quot;55%&quot; height=&quot;100%&quot; /&gt;
        &lt;ul&gt;
          &lt;li&gt;tries to make prediction look real, and has the effect of picking a particular mode from the distribution&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Region masks
 &lt;img src=&quot;/img/15942173051541.jpg&quot; width=&quot;60%&quot; height=&quot;100%&quot; /&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;central region&lt;/li&gt;
      &lt;li&gt;random block&lt;/li&gt;
      &lt;li&gt;random region (recommended)&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;Random block and random region produce a similarly general feature, while significantly outperforming the central region features.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;experiments&quot;&gt;Experiments&lt;/h4&gt;
&lt;h5 id=&quot;implementation-detail&quot;&gt;Implementation detail&lt;/h5&gt;
&lt;p&gt;Pool-free encoders: replacing all pooling layers with convolutions of the same kernel size and stride. (Intuitively, there is no reason to use pooling for reconstruction based networks.)&lt;/p&gt;

&lt;h5 id=&quot;evaluation&quot;&gt;Evaluation&lt;/h5&gt;
&lt;ol&gt;
  &lt;li&gt;Semantic Inpainting
&lt;img src=&quot;/img/15942140401143.jpg&quot; width=&quot;90%&quot; height=&quot;100%&quot; /&gt;
    &lt;ul&gt;
      &lt;li&gt;The encoder and discriminator architecture is similar to that of discriminator in [1], and decoder is similar to generator in [1].&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Feature Learning
 &lt;img src=&quot;/img/15942140603053.jpg&quot; width=&quot;90%&quot; height=&quot;100%&quot; /&gt;
    &lt;ul&gt;
      &lt;li&gt;For consistency with prior work, this paper use AlexNet as its encoder in this part.&lt;/li&gt;
      &lt;li&gt;The authors did not manage to make the adversarial loss converge with AlexNet, so they used just the reconstruction loss.&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;img src=&quot;/img/15942180841172.jpg&quot; alt=&quot;-w892&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;further-reference&quot;&gt;Further reference&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;A. Radford, L. Metz, and S. Chintala. Unsupervised representation learning with deep convolutional generative adversarial networks. ICLR, 2016.&lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Tue, 07 Jul 2020 00:00:00 -0400</pubDate>
        <link>http://localhost:4000/2020/07/07/Context-Encoders-Feature-Learning-by-Inpainting/</link>
        <guid isPermaLink="true">http://localhost:4000/2020/07/07/Context-Encoders-Feature-Learning-by-Inpainting/</guid>
        
        <category>Self-supervision</category>
        
        
      </item>
    
      <item>
        <title>Self-supervised feature learning 综述</title>
        <description>&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1902.06162.pdf&quot;&gt;Paper link&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&quot;self-supervised-feature-learning&quot;&gt;self-supervised feature learning&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;learn visual features from large-scale unlabeled images or videos without using any human annotations&lt;/li&gt;
  &lt;li&gt;a subset of unsupervised learning methods&lt;/li&gt;
  &lt;li&gt;pretext task: the supervisory signal is generated from the data itself by leveraging its structure&lt;/li&gt;
  &lt;li&gt;visual features of images or videos need to be captured by ConvNets to solve the pretext tasks&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;作用&quot;&gt;作用&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;作为pretext task获得pre-trained model
    &lt;ul&gt;
      &lt;li&gt;提供一个好的起始点，加速收敛&lt;/li&gt;
      &lt;li&gt;已经学习到hierarchy features，即使downstream task的数据集很小，也不会过拟合太严重&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;作为auxiliary task来添加regularization&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;分类&quot;&gt;分类&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;/img/15932024508723.jpg&quot; alt=&quot;-w1112&quot; /&gt;&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Information recovery: 先抹除图片的一部分信息，然后让网络学习恢复这些信息
    &lt;ul&gt;
      &lt;li&gt;generation based:
        &lt;ul&gt;
          &lt;li&gt;&lt;strong&gt;image generation&lt;/strong&gt;: help the network to capture the real distribution of the real data and generate realists data&lt;/li&gt;
          &lt;li&gt;&lt;strong&gt;color recovery&lt;/strong&gt;: network need to recognize objects and to group pixels of the same part together&lt;/li&gt;
          &lt;li&gt;&lt;strong&gt;inpainting&lt;/strong&gt;: networks are required to learn the common knowledge including the color and structure of the common objects&lt;/li&gt;
          &lt;li&gt;&lt;strong&gt;super resolution&lt;/strong&gt;: learn the semantic features of images&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;context based:
        &lt;ul&gt;
          &lt;li&gt;&lt;strong&gt;Context Similarity (contrasting)&lt;/strong&gt;: learn the invariance within one class and the variance among different classes
            &lt;ul&gt;
              &lt;li&gt;contrasting: train networks to maximum agreement of different views of same scene while minimizing agreement of views from different scenes&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;&lt;strong&gt;Spatial Context Structure&lt;/strong&gt;：learn spatial context information such as the shape of the objects and the relative positions of different parts of an object&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Hard-code program
    &lt;ul&gt;
      &lt;li&gt;This type of methods generally has two steps:
        &lt;ul&gt;
          &lt;li&gt;label generation by employing hard-code programs on images or videos to obtain labels,&lt;/li&gt;
          &lt;li&gt;train ConvNets with the generated labels.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;distill knowledge from hard-code detector&lt;/li&gt;
      &lt;li&gt;one drawback is that the semantic labels generated by hard-code detector usually are very noisy which need to specifically cope with.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Game Engines
    &lt;ul&gt;
      &lt;li&gt;game engines are able to render realistic images and provide accurate pixel-level labels&lt;/li&gt;
      &lt;li&gt;one problem is the domain gap between synthetic and real-world images&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;performance&quot;&gt;Performance&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;/img/15932060535480.jpg&quot; alt=&quot;-w913&quot; /&gt;
The performance of self-supervised methods are comparable to the supervised methods on some downstream tasks, especially for the object detection and semantic segmentation tasks.&lt;/p&gt;

</description>
        <pubDate>Fri, 26 Jun 2020 00:00:00 -0400</pubDate>
        <link>http://localhost:4000/2020/06/26/self-supervised-feature-learning/</link>
        <guid isPermaLink="true">http://localhost:4000/2020/06/26/self-supervised-feature-learning/</guid>
        
        <category>Self-supervision</category>
        
        
      </item>
    
      <item>
        <title>Distilling the Knowledge in a Neural Network</title>
        <description>&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1503.02531.pdf&quot;&gt;Paper link&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&quot;take-away-message&quot;&gt;Take away message&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;transfer the knowledge from the cumbersome model (used in training stage) to a small model (suitable for deployment)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;“knowledge”: a learned mapping from input vectors to output vectors&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;use the class probabilities produced by the cumbersome model as “soft targets” for training the small model.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;small probabilities in the soft targets define a rich similarity structure over the data, but it has very little influence on the cross-entropy cost function during the transfer stage because the probabilities are so close to zero&lt;/strong&gt;.
    &lt;ul&gt;
      &lt;li&gt;use “distillation” to raise the temperature of the final softmax until the cumbersome model produces a suitably soft set of targets.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;adding a small term to the objective function that encourages the small model to &lt;strong&gt;predict the true targets as well as matching the soft targets provided by the cumbersome model&lt;/strong&gt; works pretty well.&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;model&quot;&gt;Model&lt;/h4&gt;
&lt;h5 id=&quot;整体思路&quot;&gt;整体思路：&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;想要transfer的knowledge是从input到output的映射。也就是说，对于相同的input，希望cumbersome model和small model能生成相同的output (soft label)&lt;/li&gt;
  &lt;li&gt;用cumbersome model和small model产生的soft label做cross entropy loss
    &lt;ul&gt;
      &lt;li&gt;问题：除了hard target对应的概率，其它负标签的概率其实也提供了大量的信息。比如说一张2的图片，对应3的soft label是1e-6，而7的soft label是1e-9，说明这张图片除2之外，更像3而不像7。但是，如果使用传统的softmax层 (T=1)，我们很难有效利用这些信息，因为这些负标签的soft label太小了，基本不能影响cross entropy loss的结果&lt;/li&gt;
      &lt;li&gt;为了能利用负标签对应概率所提供的信息，使用distillation，通过增大T来产生softer probability distribution，此时正负标签对应的soft label差距将被缩小，因此负标签的soft label也能影响最终的cross entropy loss&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;知识蒸馏&quot;&gt;知识蒸馏&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;带温度T的softmax表达式：&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;q_{i}=\frac{\exp \left(z_{i}/T\right)}{\sum_{j} \exp \left(z_{j}/T \right)}&lt;/script&gt;
  &lt;/li&gt;
  &lt;li&gt;温度T的影响&lt;br /&gt;
  &lt;img src=&quot;/img/15928689216135.jpg&quot; width=&quot;70%&quot; height=&quot;100%&quot; /&gt;
    &lt;ul&gt;
      &lt;li&gt;原始的softmax函数是 $T=1$ 时的特例&lt;/li&gt;
      &lt;li&gt;温度越高，softmax后各个值z的分布就越平均，原本较小的soft label此时相对增大，对最终cross entropy loss的影响增大，也就提高了对这些原本soft label较小的负标签的关注程度&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;如何选择温度T
    &lt;ul&gt;
      &lt;li&gt;不是所有的负标签对应的soft label都是有效的：这些soft label本身是由Teacher-Net (cumbersome model) 训练得到的，因此结果一定存在noise，而且soft label越小，noise的影响越大&lt;/li&gt;
      &lt;li&gt;温度T决定了对负标签的关注程度
        &lt;ul&gt;
          &lt;li&gt;从有部分信息量的负标签中学习 –&amp;gt; 温度要高一些&lt;/li&gt;
          &lt;li&gt;防止受负标签中噪声的影响 –&amp;gt;温度要低一些&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;知识蒸馏方法&quot;&gt;知识蒸馏方法&lt;/h5&gt;
&lt;p&gt;&lt;img src=&quot;/img/15928705010652.jpg&quot; width=&quot;70%&quot; height=&quot;100%&quot; /&gt;&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;训练Teacher model&lt;/li&gt;
  &lt;li&gt;对Teacher model蒸馏，得到student distilled model
    &lt;ul&gt;
      &lt;li&gt;soft prediction loss：Teacher model和 Student model在相同温度T下产生的soft label的cross entropy loss&lt;/li&gt;
      &lt;li&gt;hard prediction loss：Student model在T=1时和groundtruth的cross entropy loss&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;note&quot;&gt;Note&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;the magnitudes of the gradients produced by the soft targets scale as $\frac{1}{T^2}$, so it is important to multiply them by $T^2$ when using both hard and soft targets&lt;/li&gt;
  &lt;li&gt;matching logits is a special case of distillation&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;参考资料&quot;&gt;参考资料&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/102038521&quot;&gt;知识蒸馏&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/61944055&quot;&gt;交叉熵与KL散度&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Sun, 21 Jun 2020 00:00:00 -0400</pubDate>
        <link>http://localhost:4000/2020/06/21/Distilling-the-Knowledge-in-a-Neural-Network/</link>
        <guid isPermaLink="true">http://localhost:4000/2020/06/21/Distilling-the-Knowledge-in-a-Neural-Network/</guid>
        
        <category>Knowledge Distillation</category>
        
        
      </item>
    
      <item>
        <title>迁移学习损失函数</title>
        <description>&lt;h4 id=&quot;基于统计量&quot;&gt;基于统计量&lt;/h4&gt;
&lt;h5 id=&quot;mmd-maximum-mean-discrepancy&quot;&gt;MMD (maximum mean discrepancy)&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;通过比较两个distribution的sample，直接获得两个distribution的差异&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://xiaohan-wang.github.io/2020/06/17/MMD/&quot;&gt;link&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;基于对抗学习&quot;&gt;基于对抗学习&lt;/h4&gt;

&lt;h4 id=&quot;参考资料&quot;&gt;参考资料&lt;/h4&gt;
</description>
        <pubDate>Wed, 17 Jun 2020 00:00:00 -0400</pubDate>
        <link>http://localhost:4000/2020/06/17/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/</link>
        <guid isPermaLink="true">http://localhost:4000/2020/06/17/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/</guid>
        
        <category>Loss</category>
        
        
      </item>
    
      <item>
        <title>估计量的无偏性、有效性、一致性</title>
        <description>&lt;h4 id=&quot;估计量&quot;&gt;估计量&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;根据样本构造一个统计量，作为总体未知参数的估计，则该统计量为估计量&lt;/li&gt;
  &lt;li&gt;估计量可视为一个随机变量
    &lt;ul&gt;
      &lt;li&gt;同一个总体可以进行多次抽样，不同的抽样结果可以计算出不同的估计量取值&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;无偏性&quot;&gt;无偏性&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;无偏估计指，估计量的数学期望等于被估计参数的真实值&lt;/li&gt;
  &lt;li&gt;例子&lt;br /&gt;
  &lt;img src=&quot;/img/15924068989806.jpg&quot; width=&quot;50%&quot; height=&quot;100%&quot; /&gt;&lt;br /&gt;
  假设圆心是被估计参数的真实值，粉色x代表每次抽样计算出的估计量。左图估计量的期望等于被估计参数的真实值，是无偏的。右图估计量的期望不等于被估计参数的真实值，是有偏的。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;有效性&quot;&gt;有效性&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;指估计量的离散程度，离散程度越小越有效&lt;/li&gt;
  &lt;li&gt;注意，有效性和无偏性是不相关的&lt;br /&gt;
  &lt;img src=&quot;/img/15924081407687.jpg&quot; width=&quot;60%&quot; height=&quot;100%&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;无偏估计不一定是最好的&lt;br /&gt;
  &lt;img src=&quot;/img/15924083443839.jpg&quot; width=&quot;50%&quot; height=&quot;100%&quot; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;一致性&quot;&gt;一致性&lt;/h4&gt;
&lt;p&gt;待填…&lt;/p&gt;

&lt;h4 id=&quot;参考资料&quot;&gt;参考资料&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.zhihu.com/question/22983179&quot;&gt;什么是无偏估计？&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/qq_40597317/article/details/80639511&quot;&gt;估计量的无偏性、有效性、一致性&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Wed, 17 Jun 2020 00:00:00 -0400</pubDate>
        <link>http://localhost:4000/2020/06/17/%E6%9C%89%E5%81%8F%E4%BC%B0%E8%AE%A1%E5%92%8C%E6%97%A0%E5%81%8F%E4%BC%B0%E8%AE%A1/</link>
        <guid isPermaLink="true">http://localhost:4000/2020/06/17/%E6%9C%89%E5%81%8F%E4%BC%B0%E8%AE%A1%E5%92%8C%E6%97%A0%E5%81%8F%E4%BC%B0%E8%AE%A1/</guid>
        
        <category>Statistics</category>
        
        
      </item>
    
      <item>
        <title>MMD</title>
        <description>&lt;p&gt;&lt;a href=&quot;https://www.aaai.org/Papers/AAAI/2007/AAAI07-262.pdf&quot;&gt;AAAI 2007 paper&lt;/a&gt; and &lt;a href=&quot;http://www.jmlr.org/papers/volume13/gretton12a/gretton12a.pdf&quot;&gt;JMLR 2012 paper&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&quot;take-away-message&quot;&gt;Take away message&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;传统的用于衡量两个概率分布P和Q差别的方法，例如KL divergence，要求概率分布P和Q已知。也就是说，&lt;strong&gt;如果我们只有来自P和Q的样本，那么我们需要先进行概率密度估计 (density estimation)，然后才能衡量两个分布的差异&lt;/strong&gt;。&lt;/li&gt;
  &lt;li&gt;MMD：利用来自P和Q的样本，直接获得它们对应的总体概率分布的差异，而无需density estimation这一中间步骤。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;mmd-metric&quot;&gt;MMD metric&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Give observations $X := {x_1, \cdots , x_m}$ and $Y := {y_1, \cdots, y_n}$, which are independently and identically distributed (i.i.d.) from distribution $p$ and $q$. Let $\mathcal{F}$ be a class of functions $f : X \to \mathbb{R}$, and shorthand notation $E_x[ f(x)] :=E_{x \sim p}[ f(x)]$ and $E_y[ f(y)] := E_{y\sim q}[ f(y)]$ denote expectations with respect to $p$ and $q$, respectively, where $x \sim p$ indicates x has distribution $p$.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Maximum mean discrepancy (MMD) is defined as:&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;MMD[\mathcal{F}, p,q] := \sup_{f \in \mathcal{F}}(E_x[ f(x)]−E_y[ f(y)]) .&lt;/script&gt;

    &lt;p&gt;We must therefore dentify a function class that is &lt;strong&gt;rich enough to uniquely identify whether $p = q$&lt;/strong&gt;. And since we want to obtain this discrepancy by sample $X$ and $Y$,  the function class should also be &lt;strong&gt;restrictive enough to provide useful finite sample estimates&lt;/strong&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Propose the unit ball in a reproducing kernel Hilbert space $\mathcal H$ as our MMD function class $\mathcal{F}$. Define &lt;strong&gt;mean embedding&lt;/strong&gt; $\mu_p(t) \in \mathcal{H}$ such that &lt;script type=&quot;math/tex&quot;&gt;E_x [f(x)] = \lt f, \mu_p \gt _{\mathcal{H}}&lt;/script&gt; for all $f \in \mathcal{H}$. If we set $f= \phi (t) = k(t, \cdot)$, we obtain $\mu_p(t) = &amp;lt;\mu_p, k(t, ·)&amp;gt;_\mathcal{H} =E_xk(t, x)$, in other words, the mean embedding of the distribution $p$ is the expectation under $p$ of the canonical feature map.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;We thus have
    &lt;center&gt; 
 $$
 \begin{split}
 MMD^2 \left[ \mathcal{F}, p,q \right] &amp;amp;= \left[ \sup_{||f||_\mathcal{H} \leq 1}(E_x [ f(x)]−E_y [ f(y)])
\right]^2\\&amp;amp;=    \left[ \sup_{||f||_\mathcal{H} \leq 1}&amp;lt;\mu_p-\mu_q,f&amp;gt;_\mathcal{H}
\right]^2\\&amp;amp;=||\mu_p-\mu_q||_\mathcal{H}^2\\&amp;amp;=||E_x\phi(x)-E_y\phi(y)||_\mathcal{H}^2
 \end{split}
 $$
 &lt;/center&gt;
  &lt;/li&gt;
  &lt;li&gt;The MMD is a metric, when $\mathcal{H}$ is a universal RKHSs, defined on a compact metric space X. It can be proven that &lt;strong&gt;the Gaussian and Laplace RKHSs&lt;/strong&gt; are universal.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;finite-sample-estimate&quot;&gt;Finite sample estimate&lt;/h4&gt;
&lt;p&gt;Given $x$ and $x^{\prime}$ independent random variables with distribution $p$, and $y$ and $y^\prime$ independent random variables with distribution $q$, the squared population MMD is&lt;/p&gt;
&lt;center&gt;
$$
MMD^2 [\mathcal{F}, p,q] = E_{x,x^\prime}
\left[k(x, x^\prime)\right] +E_{y,y^\prime}\left[ k(y, y′)\right]−2E_{x,y} \left[k(x, y)\right]
$$
&lt;/center&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;An unbiased empirical estimate
 &lt;img src=&quot;/img/15924519721534.jpg&quot; width=&quot;75%&quot; height=&quot;100%&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;An biased empirical estimate
 &lt;img src=&quot;/img/15924520728791.jpg&quot; width=&quot;75%&quot; height=&quot;100%&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;A linear time statistics&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;http://www.jmlr.org/papers/volume13/gretton12a/gretton12a.pdf&quot;&gt;link&lt;/a&gt; $P_{739}$ Lemma 14&lt;/li&gt;
      &lt;li&gt;need sufficient data (many more samples than the quadratic-cost tests)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;Estimate 1 and 2 cost $O((m+n)^2)$ time to compute both statistics&lt;/li&gt;
  &lt;li&gt;Estimate 3 can be computed in linear time&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;参考资料&quot;&gt;参考资料&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.cnblogs.com/kailugaji/p/11004246.html&quot;&gt;MATLAB最大均值差异&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

</description>
        <pubDate>Wed, 17 Jun 2020 00:00:00 -0400</pubDate>
        <link>http://localhost:4000/2020/06/17/MMD/</link>
        <guid isPermaLink="true">http://localhost:4000/2020/06/17/MMD/</guid>
        
        <category>Statistics</category>
        
        
      </item>
    
      <item>
        <title>核方法、核函数、核技巧、再生核希尔伯特空间</title>
        <description>&lt;h4 id=&quot;核方法kernel-method&quot;&gt;核方法（kernel method）&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;理论基础: Cover’s theorem，其指出，在低维空间中线性不可分的数据，通过非线性变换将其投影到高维空间之后，大概率会变为线性可分的数据&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;将低维空间的非线性可分问题，转化为高维空间的线性可分问题&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;核技巧kernel-trick&quot;&gt;核技巧（kernel trick）&lt;/h4&gt;
&lt;p&gt;设$\phi(x)$为映射函数，$\phi(x): \mathcal{X} \to \mathcal{H}$，其中$\mathcal{X}$为输入空间，$\mathcal{H}$为特征空间 (特征空间需要是Hilbert space，即完备的内积空间)。&lt;/p&gt;

&lt;p&gt;欲求$&amp;lt;\phi(x_1), \phi(x_2)&amp;gt;$：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;传统方法：先分别计算$\phi(x_1)$和$\phi(x_2)$，再在特征空间中计算二者的内积
    &lt;ul&gt;
      &lt;li&gt;缺点：当特征空间维度很大时，计算非常复杂&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;核技巧：在输入空间找到一个函数$K(x_1, x_2)$，使得$K(x_1, x_2)=&amp;lt;\phi(x_1), \phi(x_2)&amp;gt;$，从而可以直接在低维空间中计算出结果，加速核方法计算。对应的函数 $K$ 就是核函数&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;核函数kernels&quot;&gt;核函数（kernels）&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;在实际应用时，映射函数 $\phi(x)$ 不需要是已知的。换句话说，核技巧的目的就是在不需要显式地定义特征空间和映射函数的条件下，计算映射之后的内积&lt;/li&gt;
  &lt;li&gt;核函数 $K$ 本质上需要满足的条件 (不需要$\phi(x)$已知):
    &lt;ul&gt;
      &lt;li&gt;对称性: $K(\mathrm{x_1},\mathrm{x_2}) = K(\mathrm{x_2},\mathrm{x_1})$&lt;/li&gt;
      &lt;li&gt;半正定性: 对于任意 $n$ 和任意 $x_1, x_2, \cdots, x_n  \in \mathcal{X}$，由 $K(x_i, x_j)$ 定义的 Gram matrix 总是半正定的&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;只要 $K$ 是核函数，那么一定存在一个Hilbert space和一个映射函数$\phi$，使得$K(x_1, x_2)=&amp;lt;\phi(x_1), \phi(x_2)&amp;gt;$&lt;/li&gt;
  &lt;li&gt;常见核函数&lt;br /&gt;
  &lt;img src=&quot;/img/15923213053700.jpg&quot; width=&quot;90%&quot; height=&quot;100%&quot; /&gt;&lt;br /&gt;
  其它变换得到的核函数：参考资料3 $\text{P}_{17, 18}$&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;再生核希尔伯特空间reproducing-kernel-hilbert-spacesrkhs&quot;&gt;再生核希尔伯特空间（reproducing kernel Hilbert spaces，RKHS）&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;再生核希尔伯特空间
    &lt;ul&gt;
      &lt;li&gt;设 $\displaystyle \mathcal{H}$ 是希尔伯特空间，其元素为函数 $\displaystyle f:X\rightarrow R$。对于某个固定的 $\displaystyle x\in \mathcal{X}$，映射$\displaystyle \delta _{x} :H\rightarrow R,\delta _{x} :f\rightarrow f( x)$称为点 $x$ 的 (Dirac) evaluation functional&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;设 $\displaystyle \mathcal{H}$ 是希尔伯特空间，其元素为函数 $\displaystyle f:X\rightarrow R$。若对于任意的 $x \in \mathcal{X}$，$\delta_x$ 都是连续的，则 $\mathcal{H}$ 为RKHS&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;RKHS是一个函数空间，其中的元素 $f$ 为函数。通常情况下特征空间 $\mathcal{H}$ 为 RKHS。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;再生核
    &lt;ul&gt;
      &lt;li&gt;再生核 $K$ 是核函数的一种，其满足
        &lt;ul&gt;
          &lt;li&gt;对于任意固定的 $x_0\in\mathcal{X}$，$K(x,x_0)$作为 $x$ 的函数属于我们的函数空间$\mathcal{H}$&lt;/li&gt;
          &lt;li&gt;对于任意 $x\in\mathcal{X}$ 和 $f(\cdot)\in\mathcal{H}$，有 $f(x) = \langle f(\cdot),K(\cdot,x)\rangle$ (再生性质 / reproducing property)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;对于再生核 $K$，我们可以自然的定义映射函数 $\phi(x)=K(\cdot, x)$，此时，通过再生核的再生性质，可知
  &lt;script type=&quot;math/tex&quot;&gt;\langle \phi(x_1),\phi(x_2)\rangle = \langle K(\cdot,x_1),K(\cdot,x_2)\rangle = K(x_1,x_2)&lt;/script&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;关系
    &lt;ul&gt;
      &lt;li&gt;一个希尔伯特空间存在至多一个再生核 (不存在 / 存在一个)&lt;/li&gt;
      &lt;li&gt;存在再生核的希尔伯特空间就是再生核希尔伯特空间&lt;/li&gt;
      &lt;li&gt;一个再生核对应唯一的再生核希尔伯特空间&lt;/li&gt;
      &lt;li&gt;再生核和再生核希尔伯特空间是一一对应的&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;总结&quot;&gt;总结&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;一个核函数 $K$ 可能对应多个映射函数 $\phi$，而每个映射函数$\phi$ 有自己对应的特征空间 (i.e. 希尔伯特空间）
    &lt;ul&gt;
      &lt;li&gt;例子详见 参考资料6 $P_{11}$ example 35&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;任意一个核函数 $K$ 都可以作为再生核，构建其对应的唯一的再生核希尔伯特空间&lt;/li&gt;
  &lt;li&gt;对于任意一个核函数 $K$，可以存在多个对应的特征空间 $\mathcal{H_0}$，但其作为再生核只对应唯一的RKHS。同时，RKHS是所有特征空间最为“精简”的一个，这里的精简体现在，无论在 $\mathcal{H_0}$ 中得到怎样的分类模型 $⟨w,\phi_0(x)⟩_{\mathcal{H_0}}$，在RKHS中都存在一个 $f$ 可以得到和它相同的效果，因此对于某个核函数，RKHS代表了它最本征的信息。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;参考资料&quot;&gt;参考资料&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/61794781&quot;&gt;核方法、核技巧和核函数&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.fanyeong.com/2017/11/13/the-kernel-trick/&quot;&gt;核技巧&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.stat.berkeley.edu/~bartlett/courses/2014spring-cs281bstat241b/lectures/20-notes.pdf&quot;&gt;PPT&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://cosx.org/2014/05/svm-series-add-2-kernel-ii/&quot;&gt;“支持向量机系列” 的番外篇二: Kernel II&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/54704957&quot;&gt;什么是RKHS&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.gatsby.ucl.ac.uk/~gretton/coursefiles/RKHS_Notes1.pdf&quot;&gt;课程讲义&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://murongxixi.github.io/2013/11/12/%E6%A0%B8%E5%87%BD%E6%95%B0%EF%BC%8C%E5%86%8D%E7%94%9F%E6%A0%B8Hilbert%E7%A9%BA%E9%97%B4%EF%BC%8C%E8%A1%A8%E7%A4%BA%E5%AE%9A%E7%90%86/&quot;&gt;核函数，再生核Hilbert空间，表示定理&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Tue, 16 Jun 2020 00:00:00 -0400</pubDate>
        <link>http://localhost:4000/2020/06/16/%E6%A0%B8%E6%96%B9%E6%B3%95-%E6%A0%B8%E5%87%BD%E6%95%B0-%E6%A0%B8%E6%8A%80%E5%B7%A7/</link>
        <guid isPermaLink="true">http://localhost:4000/2020/06/16/%E6%A0%B8%E6%96%B9%E6%B3%95-%E6%A0%B8%E5%87%BD%E6%95%B0-%E6%A0%B8%E6%8A%80%E5%B7%A7/</guid>
        
        <category>Math</category>
        
        
      </item>
    
      <item>
        <title>AWS</title>
        <description>
&lt;h4 id=&quot;aws简介&quot;&gt;AWS简介&lt;/h4&gt;
&lt;p&gt;Amazon Web Services (AWS) 是全球最全面、应用最广泛的云平台。从全球数据中心提供涉及超过十二种类别的，超过 175 项功能齐全的服务：不仅包括计算、存储和数据库等基础设施技术，而且提供机器学习、人工智能、数据湖和分析以及物联网等新兴技术。&lt;/p&gt;

&lt;h4 id=&quot;amazon-sagemaker&quot;&gt;Amazon SageMaker&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;面向所有开发人员和数据科学家的&lt;strong&gt;机器学习服务&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;可以帮助快速构建、训练和部署机器学习 (ML) 模型&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;amazon-ec2-amazon-elastic-compute-cloud&quot;&gt;Amazon EC2 (Amazon Elastic Compute Cloud)&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;可以在云中提供安全并且可调整大小的计算容量&lt;/li&gt;
  &lt;li&gt;提供多种经过优化，适用于不同使用场景的实例类型以供选择。&lt;strong&gt;不同实例类型具有不同的 CPU、内存、存储和网络容量，可以灵活地为不同应用程序选择适当的资源组合&lt;/strong&gt;。每种实例类型都包括一种或多种实例大小，从而能够扩展资源以满足目标工作负载的要求。
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://aws.amazon.com/cn/ec2/instance-types/&quot;&gt;实例类型&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://aws.amazon.com/cn/ec2/pricing/on-demand/&quot;&gt;定价&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;参考资料&quot;&gt;参考资料&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;https://aws.amazon.com/cn/getting-started/fundamentals-overview/&lt;/li&gt;
  &lt;li&gt;https://aws.amazon.com/cn/sagemaker/?nc2=h_ql_prod_ml_sm&lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Fri, 12 Jun 2020 00:00:00 -0400</pubDate>
        <link>http://localhost:4000/2020/06/12/AWS/</link>
        <guid isPermaLink="true">http://localhost:4000/2020/06/12/AWS/</guid>
        
        <category>Tools</category>
        
        
      </item>
    
      <item>
        <title>假设检验</title>
        <description>&lt;h4 id=&quot;各种分布&quot;&gt;各种分布&lt;/h4&gt;
&lt;h5 id=&quot;正态分布&quot;&gt;正态分布&lt;/h5&gt;
&lt;p&gt;&lt;img src=&quot;/img/15919078017261.jpg&quot; width=&quot;50%&quot; height=&quot;100%&quot; /&gt;&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;$\mu \pm \sigma$ 之间的概率是68%&lt;/li&gt;
  &lt;li&gt;$\mu \pm 1.96\sigma$ 之间的概率是95%&lt;/li&gt;
  &lt;li&gt;$\mu \pm 2.56\sigma$ 之间的概率是99%&lt;/li&gt;
&lt;/ol&gt;

&lt;h5 id=&quot;其它分布&quot;&gt;其它分布&lt;/h5&gt;
&lt;p&gt;&lt;img src=&quot;/img/15919118904133.jpg&quot; width=&quot;30%&quot; height=&quot;100%&quot; /&gt;&lt;br /&gt;
和正态分布不同，需要其它方法计算对应的概率范围&lt;/p&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;假设检验&quot;&gt;假设检验&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;原假设 (Null hypothesis)&lt;/strong&gt;：也叫零假设，用 $H_0$ 来表示，一般是希望能证明为错误的假设。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;备择假设 (Alternative hypothesis)&lt;/strong&gt;：原假设的反面，一般用 $H_1$ 来表示，是希望证明是正确的另一种可能。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;检验统计量 (Test statistic)&lt;/strong&gt;：用于统计假设检验的统计量，是数据集的数字汇总，将数据减少到可用于执行假设检验的一个值。&lt;/li&gt;
  &lt;li&gt;假设检验的目的在于试图找到证据拒绝原假设。当没有足够证据拒绝原假设时，不采用 “接受原假设” 的表述，而采用 “不拒绝原假设” 的表述。“不拒绝”的表述实际上意味着并未给出明确的结论，我们没有说原假设正确，也没有说它不正确。&lt;strong&gt;假设检验的主要目的是为了拒绝而不是接受。&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;思路&quot;&gt;思路&lt;/h5&gt;
&lt;ol&gt;
  &lt;li&gt;欲证：备择假设为真&lt;/li&gt;
  &lt;li&gt;原理1: &lt;strong&gt;假设证明难而证伪易&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;只需证：备择假设的否命题（原假设）为假&lt;/li&gt;
  &lt;li&gt;原理2: &lt;strong&gt;小概率事件在少量实验中是不可能出现的&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;只需：观察到“&lt;strong&gt;原假设条件下的小概率事件&lt;/strong&gt;的发生”&lt;/li&gt;
&lt;/ol&gt;

&lt;h5 id=&quot;检验方法&quot;&gt;检验方法&lt;/h5&gt;
&lt;ol&gt;
  &lt;li&gt;首先确定“小概率事件”的概率范围，即&lt;strong&gt;显著性水平&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;e.g. 显著性水平为0.05，即发生概率小于5%的事件为“小概率事件”&lt;/li&gt;
      &lt;li&gt;显著性水平越高，“小概率事件”发生的可能性越大，即越来越容易拒绝原假设&lt;/li&gt;
      &lt;li&gt;“小概率事件”发生的区域对应&lt;strong&gt;拒绝域&lt;/strong&gt;，&lt;strong&gt;拒绝域&lt;/strong&gt;没有覆盖的区域为&lt;strong&gt;置信区间&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;如下图：设已知成绩服从正态分布，原假设为成绩均值为$\mu$，在该条件下，红色区域对应小概率事件 (发生概率为5%)，即拒绝域概率为5%，置信区间概率为95%&lt;br /&gt;
 &lt;img src=&quot;/img/15919111868762.jpg&quot; width=&quot;60%&quot; height=&quot;100%&quot; /&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;检验方法1 (临界概率 to 临界值):
    &lt;ul&gt;
      &lt;li&gt;根据设定的显著度和对应分布找到“小概率事件”对应的临界值&lt;/li&gt;
      &lt;li&gt;计算样本得到的统计量，判定是否越过了临界值&lt;/li&gt;
      &lt;li&gt;若是，则进入了小概率错误域 (拒绝域)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;检验方法2 (样本值 to 样本概率)：
    &lt;ul&gt;
      &lt;li&gt;计算样本得到的统计量，进而在分布中找到对应的概率值，即p值&lt;/li&gt;
      &lt;li&gt;将p值与显著度 (设定的“小概率事件”判定值) 进行比较&lt;/li&gt;
      &lt;li&gt;如果p值比显著度小，则发生的样本属于“小概率事件”，故而拒绝原假设&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;检验方法1和2本质上是相同的。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;错误类型&quot;&gt;错误类型&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;I类错误 (Type I error): 拒绝了正确的零假设&lt;/li&gt;
  &lt;li&gt;II类错误 (Type II error): 没有拒绝错误的零假设&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/img/15920070800446.jpg&quot; width=&quot;60%&quot; height=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;参考资料&quot;&gt;参考资料&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;https://www.zhihu.com/question/20254932&lt;/li&gt;
  &lt;li&gt;https://cosx.org/2009/03/meaning-of-failure-to-reject-h0/&lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Thu, 11 Jun 2020 00:00:00 -0400</pubDate>
        <link>http://localhost:4000/2020/06/11/%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C/</link>
        <guid isPermaLink="true">http://localhost:4000/2020/06/11/%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C/</guid>
        
        <category>Statistics</category>
        
        
      </item>
    
      <item>
        <title>从 总体 &amp; 样本 估计总体方差</title>
        <description>&lt;h4 id=&quot;用总体估计总体方差&quot;&gt;用总体估计总体方差&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;calculating population variance and std for the whole population using all the data&lt;/li&gt;
  &lt;li&gt;e.g. What is the standard deviation of last year’s returns of the 12 funds I have invested in? In this case, we have the data for the whole population available.&lt;/li&gt;
  &lt;li&gt;When using the whole population to calculate population variance, &lt;strong&gt;divide&lt;/strong&gt; the sum of squared deviations from the mean &lt;strong&gt;by the number of items in the population&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;用样本估计总体方差&quot;&gt;用样本估计总体方差&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;calculating population variance and std using only a sample of data&lt;/li&gt;
  &lt;li&gt;e.g. What is the standard deviation of last year’s returns of equity funds in the world? In this case, we don’t have all the data available and we will have to estimate the population’s standard deviation from a sample.&lt;/li&gt;
  &lt;li&gt;When using a sample to calculate population variance, &lt;strong&gt;divide it by the number of items in the sample less one&lt;/strong&gt;.&lt;/li&gt;
  &lt;li&gt;As a result, the calculated variance (and therefore also the standard deviation) will &lt;strong&gt;be slightly higher than if we would have used the population variance formula&lt;/strong&gt;. The purpose of this little difference is to get a better and unbiased estimate of the population‘s variance (by dividing by the sample size lowered by one, we &lt;strong&gt;compensate for the fact that we are working only with a sample rather than with the whole population&lt;/strong&gt;).&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;参考资料&quot;&gt;参考资料&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;https://www.macroption.com/population-sample-variance-standard-deviation/&lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Thu, 11 Jun 2020 00:00:00 -0400</pubDate>
        <link>http://localhost:4000/2020/06/11/population-and-sample-variance/</link>
        <guid isPermaLink="true">http://localhost:4000/2020/06/11/population-and-sample-variance/</guid>
        
        <category>Statistics</category>
        
        
      </item>
    
  </channel>
</rss>
