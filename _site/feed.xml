<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Xiaohan's Blog</title>
    <description>Do it now.</description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Wed, 10 Jun 2020 20:04:15 -0400</pubDate>
    <lastBuildDate>Wed, 10 Jun 2020 20:04:15 -0400</lastBuildDate>
    <generator>Jekyll v4.0.0</generator>
    
      <item>
        <title>EM algorithm, K-means, and GMM</title>
        <description>&lt;h4 id=&quot;em-algorithm&quot;&gt;EM algorithm&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;EM算法是期望最大化(Expectation Maximization)算法的简称&lt;/li&gt;
  &lt;li&gt;用于&lt;strong&gt;含有隐变量(hidden variable)&lt;/strong&gt;的情况下，模型参数的最大似然估计&lt;/li&gt;
  &lt;li&gt;EM算法是一种迭代算法，每次迭代由两步组成：
    &lt;ul&gt;
      &lt;li&gt;E步：根据模型参数的假设值，给出隐变量的期望估计，应用于缺失值&lt;/li&gt;
      &lt;li&gt;M步：根据隐变量的估计值，给出当前的参数的极大似然估计&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;k-means&quot;&gt;K-means&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;先随机选定k个点作为质心 $\mu_1, \mu_2, \cdots, \mu_𝑘$&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;E step: 固定$\mu_k$，将样本划分到距离最近的$\mu_k$所属的簇中&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
r_{nk} = \left. \begin{cases} 1 \,\, &amp; \text{if} \;\;\;k = \mathop{argmin}_j ||\mathbf{x}_n - \boldsymbol{\mu}_j||^2 \\
0 \,\, &amp; \text{otherwise} \end{cases} \right. %]]&gt;&lt;/script&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;M step: 对于每一个数据簇，重新计算其中心，目标是最小化簇中每个样本与中心的距离，可表示为&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;J = \sum\limits_{n=1}^N r_{nk} ||\mathbf{x}_n - \boldsymbol{\mu}_k||^2.&lt;/script&gt;

    &lt;p&gt;为求得最小化 $J$ 的 $\mu_k$，可通过&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{\partial J}{\partial\mathbf{\mu}_k}=2\sum\limits_{n=1}^N r_{nk}(\boldsymbol{x}_n - \boldsymbol{\mu}_k) = 0,&lt;/script&gt;

    &lt;p&gt;求得&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\boldsymbol{\mu}_k = \frac{\sum_nr_{nk} \mathbf{x}_n}{\sum_n r_{nk}},&lt;/script&gt;

    &lt;p&gt;即簇中每个样本的均值向量。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;重复计算 E-step 和 M-step 直至收敛&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;gaussian-mixture-model-gmm&quot;&gt;Gaussian Mixture Model (GMM)&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;混合模型 (mixture model)：是一个可以用来表示在总体分布中含有 K 个子分布的概率模型。换句话说，总体的概率分布，是一个由 K 个子分布组成的混合分布。
    &lt;ul&gt;
      &lt;li&gt;混合模型不要求观测数据提供其属于哪个子分布 =&amp;gt; hiddle varibale&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;对于混合模型来说，每个子分布天然地构成了各自的一类&lt;/strong&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;高斯混合模型：由 K 个单高斯模型组合而成的模型。一般来说，一个混合模型可以使用任何概率分布，这里使用高斯混合模型是因为高斯分布具备很好的数学性质以及良好的计算性能。
    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;高斯混合模型的概率分布为：&lt;/p&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;P(x|\theta) = \sum_{k=1}^{K}{\alpha_{k}\phi(x|\theta_{k})}&lt;/script&gt;
      &lt;/li&gt;
      &lt;li&gt;对于这个模型而言，参数 $\theta = (\tilde{\mu_{k}}, \tilde{\sigma_{k}}, \tilde{\alpha_{k}})$ ，也就是每个子模型的期望、方差（或协方差）、在混合模型中发生的概率&lt;/li&gt;
      &lt;li&gt;如果通过使用足够多的高斯分布，并且调节它们的均值和方差以及线性组合的系数，那么几乎所有的连续概率密度都能够以任意的精度近似。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;随机初始化模型参数（各个高斯分布的均值、方差、发生概率）&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;E step: 依据当前参数，计算每个数据 $j$ 来自子模型 $k$ 的可能性&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\gamma_{jk} = \frac{\alpha_{k}\phi(x_{j}|\theta_{k})}{\sum_{k=1}^{K}{\alpha_{k}\phi(x_{j}|\theta_{k})}}, j = 1,2,...,N; k = 1,2,...,K&lt;/script&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;M step: 计算新的模型参数&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\mu_{k} = \frac{\sum_{j=1}^{N}{(\gamma_{jk}}x_{j})}{\sum_{j=1}^{N}{\gamma_{jk}}}, k=1,2,...,K&lt;/script&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\Sigma_{k} = \frac{\sum_{j=1}^{N}{\gamma_{jk}}(x_{j}-\mu_{k})(x_{j}-\mu_{k})^{T}}{\sum_{j=1}^{N}{\gamma_{jk}}}, k = 1,2,...,K&lt;/script&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\alpha_{k} = \frac{\sum_{j=1}^{N}{\gamma_{jk}}}{N}, k=1,2,...,K&lt;/script&gt;
  &lt;/li&gt;
  &lt;li&gt;重复计算 E-step 和 M-step 直至收敛&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;difference&quot;&gt;difference&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;K-means: hard assignment&lt;/strong&gt;
in each iteration, we are absolutely certain as to which cluster the point belongs to&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;GMM: soft assignment&lt;/strong&gt;
 It starts with some prior belief about how certain we are about each point’s cluster assignments. As it goes on, it revises those beliefs&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;reference&quot;&gt;Reference&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.quora.com/What-is-the-difference-between-K-means-and-the-mixture-model-of-Gaussian&quot;&gt;difference of k-means and GMM&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://sites.northwestern.edu/msia/2016/12/08/k-means-shouldnt-be-our-only-choice/&quot;&gt;k-means shouldn’t be our only choice&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/30483076&quot;&gt;EM algorithm, K-means, and GMM 1&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/75554749&quot;&gt;EM algorithm, K-means, and GMM 2&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Tue, 09 Jun 2020 00:00:00 -0400</pubDate>
        <link>http://localhost:4000/2020/06/09/K-means%E5%92%8CGMM/</link>
        <guid isPermaLink="true">http://localhost:4000/2020/06/09/K-means%E5%92%8CGMM/</guid>
        
        <category>Clustering</category>
        
        
      </item>
    
      <item>
        <title>Image classification</title>
        <description>&lt;h4 id=&quot;cifar-10&quot;&gt;CIFAR-10&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;60000 32x32 color images in 10 classes, with 6000 images per class&lt;/li&gt;
  &lt;li&gt;50000 training images and 10000 test images&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;/img/15917518925606.jpg&quot; width=&quot;60%&quot; height=&quot;100%&quot; /&gt;&lt;/p&gt;

</description>
        <pubDate>Tue, 09 Jun 2020 00:00:00 -0400</pubDate>
        <link>http://localhost:4000/2020/06/09/Image-classification-dataset/</link>
        <guid isPermaLink="true">http://localhost:4000/2020/06/09/Image-classification-dataset/</guid>
        
        <category>Datasets</category>
        
        
      </item>
    
      <item>
        <title>slurm使用基础</title>
        <description>
&lt;p&gt;SLURM：开源作业调度系统&lt;/p&gt;

&lt;h4 id=&quot;提交作业&quot;&gt;提交作业&lt;/h4&gt;
&lt;h5 id=&quot;提交方式&quot;&gt;提交方式&lt;/h5&gt;
&lt;p&gt;Slurm提交作业有3种模式，分别为交互模式，批处理模式，分配模式。这三种方式&lt;strong&gt;只是用户使用方式的区别，而在管理，调度，记账时同等对待&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;交互模式(srun)：交互式作业提交，提交命令后，等待作业执行完成之后返回命令行窗口。&lt;/li&gt;
  &lt;li&gt;批处理模式(sbatch)：用户编写作业脚本，指定资源需求约束，提交后台执行作业。&lt;/li&gt;
  &lt;li&gt;分配模式(salloc)：结点资源抢占命令。该命令支持用户在提交作业前，抢占所需计算资源。&lt;/li&gt;
&lt;/ol&gt;

&lt;h5 id=&quot;运行参数&quot;&gt;运行参数&lt;/h5&gt;
&lt;p&gt;以下参数适用于所有作业提交命令(srun, sbatch, salloc)。&lt;strong&gt;sbatch时可以通过脚本提交或命令行提交&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;常用：&lt;/p&gt;

&lt;style&gt;
table th:first-of-type {
    width: 8%;
}
table th:nth-of-type(2) {
    width: 28%;
}
table th:nth-of-type(3) {
    width: 25%;
}
table th:nth-of-type(4) {
    width: 39%;
}
&lt;/style&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;参数&lt;/th&gt;
      &lt;th&gt;简写&lt;/th&gt;
      &lt;th&gt;作用&lt;/th&gt;
      &lt;th&gt;备注&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;-p&lt;/td&gt;
      &lt;td&gt;–partition&lt;/td&gt;
      &lt;td&gt;指定队列资源&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;–gres=gpu:&amp;lt;number&amp;gt;&lt;/td&gt;
      &lt;td&gt;每个节点的GPU数&lt;/td&gt;
      &lt;td&gt;gres是generic resource&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;-J&lt;/td&gt;
      &lt;td&gt;–job-name&lt;/td&gt;
      &lt;td&gt;指定作业名称&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;-w&lt;/td&gt;
      &lt;td&gt;–nodelist=&amp;lt;host1,host2,…&amp;gt;&lt;/td&gt;
      &lt;td&gt;在指定的节点上运行&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;其他：&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;参数&lt;/th&gt;
      &lt;th&gt;简写&lt;/th&gt;
      &lt;th&gt;作用&lt;/th&gt;
      &lt;th&gt;备注&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;-N&lt;/td&gt;
      &lt;td&gt;–nodes=&amp;lt;number&amp;gt;&lt;/td&gt;
      &lt;td&gt;指定节点数量&lt;/td&gt;
      &lt;td&gt;是节点数，不是CPU核数，实际分配的是节点数×每节点CPU核数&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;-n&lt;/td&gt;
      &lt;td&gt;–ntasks=&amp;lt;number&amp;gt;&lt;/td&gt;
      &lt;td&gt;运行&amp;lt;number&amp;gt;个任务&lt;/td&gt;
      &lt;td&gt;默认为每个节点一个任务，注意是所需总CPU核数&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;–ntasks-per-node=&amp;lt;ntasks&amp;gt;&lt;/td&gt;
      &lt;td&gt;每个节点运行&amp;lt;ntasks&amp;gt;个任务&lt;/td&gt;
      &lt;td&gt;需与-n=&amp;lt;number&amp;gt;配合&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;–ntasks-per-core=&amp;lt;ntasks&amp;gt;&lt;/td&gt;
      &lt;td&gt;每颗CPU核运行&amp;lt;ntasks&amp;gt;个任务&lt;/td&gt;
      &lt;td&gt;需与-n=&amp;lt;number&amp;gt;配合，并自动绑定&amp;lt;ntasks&amp;gt;个任务到每个CPU核&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h4 id=&quot;查看信息&quot;&gt;查看信息&lt;/h4&gt;
&lt;h5 id=&quot;队列&quot;&gt;队列&lt;/h5&gt;
&lt;ol&gt;
  &lt;li&gt;sinfo：显示队列中各个节点的状态（idle, mix, alloc, drain）
    &lt;ul&gt;
      &lt;li&gt;idle，表示节点处于空闲状态&lt;/li&gt;
      &lt;li&gt;mix，节点具有分配CPU的作业，而其他的CPU状态是IDLE，新提交的作业继续运行&lt;/li&gt;
      &lt;li&gt;alloc，节点所有CPU都被占用，新提交的作业将排队&lt;/li&gt;
      &lt;li&gt;drain，出现这个状态时，不影响正在运行的作业，但是不接受新的作业调度，可以使用命令sinfo –R打印节点不正常的状态产生原因&lt;/li&gt;
      &lt;li&gt;down 故障节点不可用&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;scontrol show partition &amp;lt;partition name&amp;gt;：显示队列详细信息&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;作业&quot;&gt;作业&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;squeue：显示排队和运行中的作业（可以设置参数限制显示范围，e.g. -u显示特定user的作业）&lt;/li&gt;
  &lt;li&gt;scontrol show job &amp;lt;job id&amp;gt;：实时作业详细信息&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;节点&quot;&gt;节点&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;scontrol show node &amp;lt;node name&amp;gt;：显示节点状态
    &lt;ul&gt;
      &lt;li&gt;CfgTRES: 该节点的总资源（TRES表示Trackable Resource）
        &lt;ul&gt;
          &lt;li&gt;CfgTRES=cpu=32,mem=257828M,billing=32,gres/gpu=8&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;AllocTRES: 已经分配的资源
        &lt;ul&gt;
          &lt;li&gt;AllocTRES=cpu=4,mem=8800M,gres/gpu=2：已经占用 了 4 个 CPU 核心，8800 MB 内存和 2 块 GPU 卡&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;简单使用方法&quot;&gt;简单使用方法&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;sinfo -&amp;gt; 查看总体GPU使用情况&lt;/li&gt;
  &lt;li&gt;scontrol show node &amp;lt;node name&amp;gt; -&amp;gt; 查看具体节点GPU剩余情况&lt;/li&gt;
  &lt;li&gt;sbatch -w &amp;lt;node name&amp;gt; –gres=gpu:&amp;lt;number&amp;gt; train.sh -&amp;gt; 在相应节点上request对应的GPU资源&lt;/li&gt;
  &lt;li&gt;scontrol show job &amp;lt;jobid&amp;gt; -&amp;gt; 查看任务详细信息&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;在申请相应资源后，任务只能&lt;strong&gt;获取到&lt;/strong&gt;对应部分资源。比如说，无论节点总体的GPU使用情况如何 (e.g. 一共8个GPU，已占用3个)，若–gres=gpu:4 (申请了4个GPU)，那么程序的CUDA_VISIBLE_DEVICES=0,1,2,3&lt;/p&gt;

&lt;h4 id=&quot;参考资料&quot;&gt;参考资料&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.hpccube.com/wiki/index.php/SLURM%E4%BD%BF%E7%94%A8%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B#.E6.96.87.E6.A1.A3.E6.A6.82.E8.BF.B0&quot;&gt;SLURM使用基础教程&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://hmli.ustc.edu.cn/doc/userguide/slurm-userguide.pdf&quot;&gt;Slurm作业调度系统使用指南&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Fri, 05 Jun 2020 00:00:00 -0400</pubDate>
        <link>http://localhost:4000/2020/06/05/slurm/</link>
        <guid isPermaLink="true">http://localhost:4000/2020/06/05/slurm/</guid>
        
        <category>Linux</category>
        
        
      </item>
    
      <item>
        <title>多卡训练</title>
        <description>
&lt;h4 id=&quot;cuda_visible_devices&quot;&gt;CUDA_VISIBLE_DEVICES&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;CUDA_VISIBLE_DEVICES环境变量限制CUDA程序可见的GPU设备&lt;/li&gt;
  &lt;li&gt;CUDA应用运行时，CUDA将遍历当前&lt;strong&gt;可见的&lt;/strong&gt;设备，并从零开始为可见设备编号（因此显卡的实际编号和程序看到的编号不同）&lt;/li&gt;
  &lt;li&gt;如果设备序列是存在和不存在设备的混合，那么不存在设备前的所有存在设备将被重新编号，不存在设备之后的所有设备将被屏蔽&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;在终端中设置
 &lt;code class=&quot;highlighter-rouge&quot;&gt;CUDA_VISIBLE_DEVICES=0,1 python my_script.py&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;python代码开头设置
 &lt;code class=&quot;highlighter-rouge&quot;&gt;os.environ[&quot;CUDA_VISIBLE_DEVICES&quot;] = &quot;0,2&quot;&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;pytorch使用gpu&quot;&gt;PyTorch使用GPU&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;data.cuda()&lt;/code&gt;: the old, pre-0.4 way&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;data.to(device)&lt;/code&gt;: more flexible. For example, &lt;code class=&quot;highlighter-rouge&quot;&gt;data.to('cuda:1')&lt;/code&gt; put data to GPU1&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;单机单卡&quot;&gt;单机单卡&lt;/h4&gt;
&lt;p&gt;如果不设置Dataparallel，即使一台机器上有多个GPU，pytorch也只会占用编号为0的GPU&lt;/p&gt;

&lt;h4 id=&quot;单机多卡&quot;&gt;单机多卡&lt;/h4&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# have to put model and data to GPU0
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# model
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataParallel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'cuda:0'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# data
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'cuda:0'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;nn.DataParallel&lt;/code&gt;默认使用可见的所有显卡。如果只想使用特定的显卡，可以&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;修改CUDA_VISIBLE_DEVICES环境变量&lt;/li&gt;
  &lt;li&gt;使用&lt;code class=&quot;highlighter-rouge&quot;&gt;nn.DataParallel(model, device_ids=[1,2])&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Note：&lt;code class=&quot;highlighter-rouge&quot;&gt;nn.DataParallel&lt;/code&gt;返回的model是DataParallel，而不是原来的model。原来的model被保存在返回的model的module属性中(model.module)&lt;/strong&gt;&lt;/p&gt;

&lt;h4 id=&quot;多机多卡&quot;&gt;多机多卡&lt;/h4&gt;
&lt;p&gt;待填&lt;/p&gt;

&lt;h4 id=&quot;参考资料&quot;&gt;参考资料&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;https://www.jianshu.com/p/0816c3a5fa5c&lt;/li&gt;
  &lt;li&gt;https://zhuanlan.zhihu.com/p/86441879&lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Thu, 04 Jun 2020 00:00:00 -0400</pubDate>
        <link>http://localhost:4000/2020/06/04/PyTorch%E5%A4%9A%E5%8D%A1%E8%AE%AD%E7%BB%83/</link>
        <guid isPermaLink="true">http://localhost:4000/2020/06/04/PyTorch%E5%A4%9A%E5%8D%A1%E8%AE%AD%E7%BB%83/</guid>
        
        <category>PyTorch</category>
        
        
      </item>
    
      <item>
        <title>语义分割评价指标</title>
        <description>
&lt;h4 id=&quot;评价指标&quot;&gt;评价指标&lt;/h4&gt;
&lt;p&gt;Let $n_{ij}$ be the number of pixels of class $i$ predicted to belong to class $j$, where there are $n_{cl}$ different classes, and let $t_i=\sum_jn_{ij}$ be the total number of pixels of class $i$.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;pixel accuracy: $\frac{\sum\limits_i n_{ii}}{\sum\limits_i t_{i}}$&lt;/li&gt;
  &lt;li&gt;mean pixel accuracy $\frac{1}{n_{cl}}\sum\limits_i \frac{n_{ii}}{ t_{i}}$&lt;/li&gt;
  &lt;li&gt;mean IoU: $\frac{1}{n_{cl}}\sum\limits_i \frac{n_{ii}}{t_i+\sum\limits_j n_{ji}-n_{ii}}$&lt;/li&gt;
  &lt;li&gt;frequency weighted IoU $\frac{1}{\sum\limits_k t_k}\sum\limits_i \frac{t_i n_{ii}}{t_i+\sum\limits_j n_{ji}-n_{ii}}$&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;reference&quot;&gt;Reference&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;Fully Convolutional Networks for Semantic Segmentation&lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Mon, 01 Jun 2020 00:00:00 -0400</pubDate>
        <link>http://localhost:4000/2020/06/01/segmentation-metrics/</link>
        <guid isPermaLink="true">http://localhost:4000/2020/06/01/segmentation-metrics/</guid>
        
        <category>Metrics</category>
        
        
      </item>
    
      <item>
        <title>语义分割损失函数</title>
        <description>
&lt;p&gt;&lt;strong&gt;Note： 以下虽然将预测结果称为概率，但其本身并不具有概率的内在含义，其本质上只是各个类别的得分情况。&lt;/strong&gt;&lt;/p&gt;

&lt;h4 id=&quot;cross-entropy系列&quot;&gt;cross entropy系列&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;把每个像素看作一个单独的sample&lt;/li&gt;
  &lt;li&gt;整个图像的loss是所有像素loss的（加权）平均值&lt;/li&gt;
  &lt;li&gt;实际使用中，可以用weighted focal loss：$\text{pixel loss}=-\sum\limits_{classes}\alpha_{class}(1-y_{pred})^\gamma \times y_{true}log(y_{pred})$，以同时解决难学习样本问题和样本数量不均衡问题&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;basic-ce-loss&quot;&gt;basic CE loss&lt;/h5&gt;
&lt;ol&gt;
  &lt;li&gt;cross entropy loss （ce loss）
    &lt;ul&gt;
      &lt;li&gt;适用于二分类及多分类问题&lt;/li&gt;
      &lt;li&gt;用多通道one-hot标签表示ground-truth。prediction同样为多通道，每个通道表示属于各个类的概率&lt;/li&gt;
      &lt;li&gt;用一个像素的预测结果（概率分布向量）和它的one-hot标签向量比较，得到该像素的损失：$\text{pixel loss}=-\sum\limits_{classes}y_{true}log(y_{pred})=-log(y_{\text{true_pred}})$。化简后的结果就是该像素的真实类别所对应的预测值的负log值。&lt;br /&gt;
 &lt;img src=&quot;/img/15907867544949.jpg&quot; width=&quot;50%&quot; height=&quot;100%&quot; /&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;binary cross entropy loss （bce loss）
    &lt;ul&gt;
      &lt;li&gt;适用于二分类问题&lt;/li&gt;
      &lt;li&gt;单通道图表示ground truth，0为负样本，1为正样本。prediction同样为单通道，表示为1（正样本）的概率&lt;/li&gt;
      &lt;li&gt;每个像素的损失为：$\text{bce loss}=-y_{true}log(y_{pred})-(1-y_{true})log(1-y_{pred})$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h5 id=&quot;weighed-ce-loss&quot;&gt;weighed CE loss&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;针对在图像中多个类的样本不均衡问题&lt;/strong&gt;。基本的交叉熵损失为各个像素损失的平均值，也就是平等的对待各个像素（样本）。&lt;strong&gt;此时如果多个类的样本数量分布不均衡，图像最终的损失将由样本数量多的类别对应的损失所主导，导致模型会主要学习样本数量多的类别的特征，并且学习出来的模型会更偏向将像素预测为该类别&lt;/strong&gt;。&lt;/li&gt;
  &lt;li&gt;为了避免图像最终的损失由样本数量多的类别对应的损失所主导，可以选择增大样本数量少的类的损失，即为不同样本数量的类别对应的损失添加不同的权重&lt;/li&gt;
  &lt;li&gt;加权交叉熵损失函数：$\text{pixel loss}=-\sum\limits_{classes}\alpha_{class}\times y_{true}log(y_{pred})$，其中 $\alpha_{class}$ 对应不同类别的权重&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;focal-loss&quot;&gt;focal loss&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;使网络更加关注难学习样本&lt;/strong&gt;。当图像中存在大量的易学习像素（对应类别的 $y_{pred}&amp;gt;0.5$）和少量的难学习像素（对应类别的 $y_{pred}&amp;lt;0.5$）时，虽然易学习像素的loss小于难学习像素的loss，但由于样本数量的影响，&lt;strong&gt;大量易学习像素总体的loss也将远远超过少量难学习像素总体的loss，使得图像最终的loss由大量易学习像素的loss所主导，导致模型趋向于继续关注大量易学习的样本，而不会关注难学习的样本&lt;/strong&gt;。&lt;/li&gt;
  &lt;li&gt;focal loss修改交叉熵损失函数为：$\text{pixel loss}=-\sum\limits_{classes}(1-y_{pred})^\gamma \times y_{true}log(y_{pred})$，其中 $y_{pred}$ 越小（越难学习），对应的权重越大。实验表明 $\gamma=2$ 效果最好。&lt;/li&gt;
  &lt;li&gt;focal loss也一定程度上解决了样本数量不平衡问题。因为样本数量少的类别对应的像素往往也是难学习的像素，因此关注难学习样本有助于关注样本数量少的类别。
&lt;img src=&quot;/img/15908083180433.jpg&quot; width=&quot;60%&quot; height=&quot;100%&quot; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;dice-loss系列&quot;&gt;dice loss系列&lt;/h4&gt;
&lt;p&gt;待填…&lt;/p&gt;

&lt;h4 id=&quot;参考资料&quot;&gt;参考资料&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/101773544&quot;&gt;link1&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://niecongchong.github.io/2019/08/06/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E6%80%BB%E7%BB%93/&quot;&gt;link2&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Fri, 29 May 2020 00:00:00 -0400</pubDate>
        <link>http://localhost:4000/2020/05/29/segmentation-loss/</link>
        <guid isPermaLink="true">http://localhost:4000/2020/05/29/segmentation-loss/</guid>
        
        <category>Loss</category>
        
        
      </item>
    
      <item>
        <title>Learning rate scheduler</title>
        <description>
&lt;h4 id=&quot;take-away-message&quot;&gt;Take away message&lt;/h4&gt;
&lt;p&gt;总体来说，学习率呈现“上升——平稳——下降”的规律。&lt;/p&gt;

&lt;h4 id=&quot;warm-up&quot;&gt;Warm up&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;减缓模型在训练初期过拟合mini-batch  &lt;br /&gt;
 个人猜测：
    &lt;ul&gt;
      &lt;li&gt;在第一轮训练的时候（尤其是训练刚开始），模型只见过部分数据，此时梯度大概率是偏离相对全局真正较优的方向的（此时很大概率是过拟合当前小部分数据的方向），因此需要使用较小的学习率，以免对当前小部分数据过拟合，对后面训练造成影响（影响有两种可能：1）需要后面多轮训练来修正之间的偏差；2）偏差太大，后面多轮训练也没用，最后accuracy下降）。&lt;/li&gt;
      &lt;li&gt;当训练了一段时间（比如两轮、三轮）后，模型见过了全部数据，此时梯度基本符合相对全局真正较优的方向，所以可以适当调大学习率。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;有助于保持模型深层的稳定性&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;learning-rate-decay&quot;&gt;Learning rate decay&lt;/h4&gt;
&lt;p&gt;学习率衰减的基本思想是学习率随着训练的进行逐渐衰减，即在开始的时候使用较大的学习率，加快靠近最小值的速度，在后来些时候用较小的学习率，提高稳定性，避免因学习率太大跳过最小值，保证能够收敛到最小值。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;step(固定步长衰减): 每隔step_size个epoch后，lr衰减为原来的gamma倍&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/img/15906775729941.jpg&quot; width=&quot;50%&quot; height=&quot;100%&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;multistep(多步长衰减): 动态步长控制，lr衰减为原来的gamma倍&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/img/15906776874073.jpg&quot; width=&quot;50%&quot; height=&quot;100%&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;poly(多项式衰减): $lr = \text{base_lr} * (1 - \frac{T_{cur}}{T_{max}}) ^ {power} $
    &lt;ul&gt;
      &lt;li&gt;学习率曲线的形状主要由参数 power 的值来控制。当 power = 1 的时候，学习率曲线为一条直线。当 power &amp;lt; 1 的时候，下降速率由慢到快。当 power &amp;gt; 1 的时候，下降速率由快到慢。
 &lt;img src=&quot;/img/15906784236558.jpg&quot; width=&quot;85%&quot; height=&quot;100%&quot; /&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;cosine(余弦衰减): $lr = \frac{1}{2}*\text{base_lr} * \left(1+ \cos\left(\frac{T_{cur}}{T_{max}}\pi\right)\right)$
    &lt;ul&gt;
      &lt;li&gt;余弦值首先缓慢下降，然后加速下降，之后再次缓慢下降。&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;img src=&quot;/img/15906782692333.jpg&quot; width=&quot;50%&quot; height=&quot;100%&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;warm-restart&quot;&gt;Warm restart&lt;/h4&gt;
&lt;p&gt;TODO&lt;/p&gt;

&lt;h4 id=&quot;参考资料&quot;&gt;参考资料&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.zhihu.com/question/338066667&quot;&gt;warm up&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://lumingdong.cn/setting-strategy-of-gradient-descent-learning-rate.html&quot;&gt;cosine&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/39565465&quot;&gt;poly&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/93624972&quot;&gt;step and multistep&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

</description>
        <pubDate>Thu, 28 May 2020 00:00:00 -0400</pubDate>
        <link>http://localhost:4000/2020/05/28/learning-rate/</link>
        <guid isPermaLink="true">http://localhost:4000/2020/05/28/learning-rate/</guid>
        
        <category>Model Training</category>
        
        
      </item>
    
      <item>
        <title>batch size与learning rate</title>
        <description>&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1706.02677.pdf&quot;&gt;Paper link&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&quot;take-away-message&quot;&gt;Take away message&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;当满足一定条件下，batch_size增大k倍时，lr可以直接相应增大k倍&lt;/li&gt;
  &lt;li&gt;训练初期不满足1)所需的条件，此时lr需要使用warm up&lt;/li&gt;
  &lt;li&gt;underlying loss function受batch size影响。为了不改变underlying loss function，在增大batch_size时，其实并不是改变per-worker sample size n，而是增大the number of workers k&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;linear-scaling-rule&quot;&gt;Linear Scaling Rule&lt;/h4&gt;
&lt;p&gt;设有 k 个mini-batch $B_0, \cdots, B_{k-1}$:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;$lr=\eta$, 使用小batch_size $B_j$训练，共训 k 个iteration（$j=0, \cdots, k-1$）：&lt;br /&gt;
 &lt;img src=&quot;/img/15906983171534.jpg&quot; width=&quot;40%&quot; height=&quot;100%&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;$lr = \hat{\eta}$, 使用大batch-size $\cup_j{B_j}$训一个iteration：
 &lt;img src=&quot;/img/15906986727563.jpg&quot; width=&quot;40%&quot; height=&quot;100%&quot; /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;1和2对应不同的更新方式，因此不太可能有$\hat w_{t+1} = w_{t+k}$。但是，&lt;strong&gt;如果我们假设$\nabla l(x,w_t) \approx \nabla l(x,w_{t+j})$ for $j &amp;lt; k$，那么在 $\hat \eta =k\eta$ 条件下能推出 $\hat w_{t+1} \approx  w_{t+k}$，即使用不同batch-size得到相似的更新结果&lt;/strong&gt;。&lt;/p&gt;

&lt;h4 id=&quot;warm-up&quot;&gt;Warm up&lt;/h4&gt;
&lt;p&gt;在训练的开始阶段，模型权重迅速改变，不满足linear scaling rule中的条件。此时使用gradual warmup有助于解决训练中出现的问题。&lt;/p&gt;

&lt;h4 id=&quot;batch-normalization&quot;&gt;Batch normalization&lt;/h4&gt;
&lt;p&gt;如果有BN层，那么每个sample的loss其实并不是独立的，而是与其所在的mini-batch有关（因为会根据每个mini-batch的mean/std做normalization）。由于不同的mini-batch size会导致不同的mean/variance statistics distribution，因此改变mini-batch size会改变underlying loss function。&lt;/p&gt;

&lt;p&gt;为了不改变underlying loss function，根据上述分析，在增大mini-batch size时，我们其实不应该改变per-worker sample size n（batch statistics是在每个worker上单独计算的），而是应该增大the number of workers k。通常n=32在大部分数据集和网络上都表现良好。&lt;/p&gt;

</description>
        <pubDate>Thu, 28 May 2020 00:00:00 -0400</pubDate>
        <link>http://localhost:4000/2020/05/28/batch-size%E4%B8%8Elearning-rate/</link>
        <guid isPermaLink="true">http://localhost:4000/2020/05/28/batch-size%E4%B8%8Elearning-rate/</guid>
        
        <category>Model Training</category>
        
        
      </item>
    
      <item>
        <title>Image Preprocessing</title>
        <description>
&lt;p&gt;原文：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;https://medium.com/nanonets/how-to-use-deep-learning-when-you-have-limited-data-part-2-data-augmentation-c26971dc8ced&lt;/li&gt;
  &lt;li&gt;https://freecontent.manning.com/the-computer-vision-pipeline-part-3-image-preprocessing/&lt;/li&gt;
  &lt;li&gt;https://www.codecademy.com/articles/normalization&lt;/li&gt;
  &lt;li&gt;https://www.infoq.cn/article/kyXx3sRKNsdFgqapv2Gw&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;No free lunch theorem for optimization:
In ML project, it means that there’s no single prescribed recipe that is guaranteed to work well in all situations. We must make certain assumption about the dataset and the problem we are trying to solve.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;why-image-preprocessing&quot;&gt;why image preprocessing&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;The acquired data are usually messy and come from different sources, they need to be standardized and cleaned up.&lt;/li&gt;
  &lt;li&gt;We can’t write a unique algorithm for each of the condition in which an image is taken, thus, when we acquire an image, we tend to convert it into a form that allows a general algorithm to solve it.&lt;/li&gt;
  &lt;li&gt;It can reduce the complexity and increase the accuracy of the applied algorithm.&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;彩色图像--灰度图像&quot;&gt;彩色图像 / 灰度图像&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;In many objects, color isn’t necessary to recognize and interpret an image. Grayscale can be good enough for recognizing certain objects. Because color images contain more information than black and white images, they can add unnecessary complexity and take up more space in memory.
 &lt;img src=&quot;/img/15904315018825.jpg&quot; width=&quot;100%&quot; height=&quot;100%&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;In other applications, color is important to define certain objects. Like skin cancer detection which relies heavily on the skin colors (red rashes).&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;standardize-image&quot;&gt;Standardize Image&lt;/h4&gt;
&lt;h5 id=&quot;reason&quot;&gt;Reason&lt;/h5&gt;
&lt;ol&gt;
  &lt;li&gt;If we didn’t scale our input training vectors, the ranges of our distributions of feature values would likely be different for each feature, and thus the learning rate would &lt;strong&gt;cause corrections in each dimension that would differ (proportionally speaking) from one another&lt;/strong&gt;. We might be over compensating a correction in one weight dimension while undercompensating in another.&lt;/li&gt;
  &lt;li&gt;In the process of training our network, we’re going to be multiplying (weights) and adding to (biases) these initial inputs in order to cause activations that we then backpropogate with the gradients to train the model. We’d like in this process for each feature to have a similar range so that our &lt;strong&gt;gradients don’t go out of control&lt;/strong&gt;.&lt;/li&gt;
&lt;/ol&gt;

&lt;h5 id=&quot;ways&quot;&gt;ways&lt;/h5&gt;
&lt;ol&gt;
  &lt;li&gt;Min-max normalization $\frac{\text{value}-\text{min}}{\text{max}-\text{min}}$: Guarantees all features will have the exact same scale but does not handle outliers well.&lt;br /&gt;
 &lt;img src=&quot;/img/15904331747160.jpg&quot; width=&quot;60%&quot; height=&quot;100%&quot; /&gt;&lt;br /&gt;
 Normalizing fixed the squishing problem on the y-axis, but the x-axis is still problematic. Now if we were to compare these points, the y-axis would dominate; the y-axis can differ by 1, but the x-axis can only differ by 0.4.&lt;/li&gt;
  &lt;li&gt;Z-score normalization $\frac{value-mean}{std}$: Handles outliers, but does not produce normalized data with the exact same scale.&lt;br /&gt;
 &lt;img src=&quot;/img/15904332447812.jpg&quot; width=&quot;60%&quot; height=&quot;100%&quot; /&gt;&lt;br /&gt;
 While the data still looks squished, notice that the points are now on roughly the same scale for both features — almost all points are between -2 and 2 on both the x-axis and y-axis.&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;data-augmentation&quot;&gt;Data Augmentation&lt;/h4&gt;

&lt;h5 id=&quot;分类&quot;&gt;分类&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;有监督的数据增强：采用预设的数据变换规则，在已有数据的基础上进行数据的扩增
    &lt;ul&gt;
      &lt;li&gt;单样本数据增强：增强一个样本的时候，全部围绕着该样本本身进行操作
        &lt;ul&gt;
          &lt;li&gt;几何操作类：对图像进行几何变换，包括翻转，旋转，裁剪，变形，缩放等各类操作
            &lt;ul&gt;
              &lt;li&gt;可能会引入图像边界之外的位置，导致没有图像没有覆盖的黑色区域，此时可以通过常数、边缘、反射、对称等方式填充未知区域&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;颜色变换类：改变图像本身的内容，包括噪声、模糊、颜色变换（HSV，对比度变换）、擦除、填充
            &lt;ul&gt;
              &lt;li&gt;高斯噪声：当神经网络试图学习可能并无用处的高频特征时（即频繁发生的无意义模式），常常会发生过拟合。具有零均值特征的高斯噪声本质上就是在所有频率上都有数据点，能有效使得高频特征失真，减弱它对模型的影响。这也意味着低频成分（通常也是我们关心的数据）也会失真，但神经网络能够通过学习忽略这部分影响。添加正确数量的噪声就能增强神经网络的学习能力。&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;多样本数据增强方法：利用多个样本来产生新的样本
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;https://www.jair.org/index.php/jair/article/view/10302/24590&quot;&gt;SMOTE&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1801.02929.pdf&quot;&gt;SamplePairing&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1710.09412.pdf&quot;&gt;mixup&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;SMOTE，SamplePairing，mixup 三者思路上有相同之处，都是试图将离散样本点连续化来拟合真实样本分布，不过所增加的样本点在特征空间中仍位于已知小样本点所围成的区域内。如果能够在给定范围之外适当插值，也许能实现更好的数据增强效果。&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;无监督的数据增强方法
    &lt;ul&gt;
      &lt;li&gt;生成新的数据: 通过模型学习数据的分布，随机生成与训练数据集分布一致的图片，代表方法 &lt;a href=&quot;https://arxiv.org/pdf/1406.2661.pdf&quot;&gt;GAN&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;学习增强策略: 通过模型，学习出适合当前任务的数据增强方法，代表方法 &lt;a href=&quot;https://arxiv.org/pdf/1805.09501.pdf&quot;&gt;AutoAugment&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;offline--online-augmentation&quot;&gt;Offline / Online augmentation&lt;/h5&gt;
&lt;ol&gt;
  &lt;li&gt;Offline augmentation:
    &lt;ul&gt;
      &lt;li&gt;事先进行所有必需的图像平移工作，基本上就是增加数据集大小&lt;/li&gt;
      &lt;li&gt;当数据集相对较小时，优先选择这种方法，因为会将数据集增大N倍（N=执行的转换数量）&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Online augmentation:
    &lt;ul&gt;
      &lt;li&gt;将图像输入机器学习模型之前，以小批量进行图像平移&lt;/li&gt;
      &lt;li&gt;比较适合数据集较大时的情况，因为我们很难应付数据集爆炸性变大。相反，我们可以小批量平移输入到模型中的图像。有些机器学习框架支持在线增强，使用GPU可以加快增强速度。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

</description>
        <pubDate>Mon, 25 May 2020 00:00:00 -0400</pubDate>
        <link>http://localhost:4000/2020/05/25/image-preprocessing/</link>
        <guid isPermaLink="true">http://localhost:4000/2020/05/25/image-preprocessing/</guid>
        
        <category>Model Training</category>
        
        
      </item>
    
      <item>
        <title>Identity mapping</title>
        <description>&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1603.05027.pdf&quot;&gt;Paper link&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&quot;take-away-message&quot;&gt;Take away message&lt;/h4&gt;
&lt;p&gt;The forward and backward signals can be directly propagated from one block to any other block, when using identity mappings as 1) the skip connections and 2) after-addition activation. This makes training easier and improves generalization.&lt;/p&gt;

&lt;h4 id=&quot;model&quot;&gt;Model&lt;/h4&gt;
&lt;p&gt;Residual unit:
&lt;img src=&quot;/img/15902038485632.jpg&quot; width=&quot;25%&quot; height=&quot;100%&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;$x_l$ and $x_{l+1}$ are input and output of the $l$-th unit&lt;/li&gt;
  &lt;li&gt;$F$ is a residual function&lt;/li&gt;
  &lt;li&gt;$h(x_l) $ is an skip connection&lt;/li&gt;
  &lt;li&gt;$f$ is an after-addition activation function.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;If (i) skip connection is identity mapping $h(x_l) = x_l$, and (ii) after-addition activation $f$ is an identity mapping, then we have
&lt;img src=&quot;/img/15902041544783.jpg&quot; width=&quot;30%&quot; height=&quot;100%&quot; /&gt;
&lt;img src=&quot;/img/15902041725422.jpg&quot; width=&quot;50%&quot; height=&quot;100%&quot; /&gt;
that is, the signal can be directly propagated from any unit to another, both forward and backward.&lt;/strong&gt;&lt;/p&gt;

&lt;h5 id=&quot;identity-skip-connections&quot;&gt;Identity Skip Connections&lt;/h5&gt;
&lt;p&gt;&lt;img src=&quot;/img/15902046739782.jpg&quot; width=&quot;81%&quot; height=&quot;100%&quot; /&gt;
&lt;img src=&quot;/img/15902049097732.jpg&quot; width=&quot;80%&quot; height=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;As indicated by the grey arrows in Fig. 2, the shortcut connections are the most direct paths for the information to propagate. Multiplicative manipulations (scaling, gating, 1×1 convolutions, and dropout) on the shortcuts can hamper information propagation and lead to optimization problems.&lt;/p&gt;

&lt;h5 id=&quot;activation-functions&quot;&gt;Activation Functions&lt;/h5&gt;
&lt;p&gt;&lt;img src=&quot;/img/15902048739817.jpg&quot; width=&quot;80%&quot; height=&quot;100%&quot; /&gt;
&lt;img src=&quot;/img/15902048935542.jpg&quot; width=&quot;80%&quot; height=&quot;100%&quot; /&gt;&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;(a) original residual unit&lt;/li&gt;
  &lt;li&gt;(b) BN after addition
    &lt;ul&gt;
      &lt;li&gt;the BN layer alters the signal that passes through the shortcut and impedes information propagation&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;(c) ReLU before addition
    &lt;ul&gt;
      &lt;li&gt;a non-negative output from the transform $F$, while intuitively a “residual” function should take values in $(-\infty, +\infty)$. As a result, the forward propagated signal is monotonically increasing, which may impact the representational ability.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;pre-activation: develop an asymmetric form where an activation $f$ only affect the residual path but not the both paths in the next Residual Unit (i.e. move the activation module in a) and b) to the residual path, which become d) and e))
    &lt;ul&gt;
      &lt;li&gt;(d) This ReLU layer is not used in conjunction with a BN layer, and may not enjoy the benefits of BN.&lt;/li&gt;
      &lt;li&gt;(e)  result is good&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Benefit of pre-activation&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Ease of optimization
    &lt;ul&gt;
      &lt;li&gt;the benefit of ease of optimization is more obvious in 1001-layer network than networks with fewer layers.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Reducing overfitting
    &lt;ul&gt;
      &lt;li&gt;The pre-activation version reaches slightly higher training loss at convergence, but produces lower test error. This phenomenon is observed on ResNet-110, ResNet-110(1-layer), and ResNet-164 on both CIFAR-10 and 100.&lt;/li&gt;
      &lt;li&gt;In the original Residual Unit (Fig. 4(a)), although the BN normalizes the signal, this is soon added to the shortcut and thus the merged signal is not normalized. This unnormalized signal is then used as the input of the next weight layer. On the contrary, in the pre-activation version, the inputs to all weight layers have been normalized.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Fri, 22 May 2020 00:00:00 -0400</pubDate>
        <link>http://localhost:4000/2020/05/22/Identity-mapping/</link>
        <guid isPermaLink="true">http://localhost:4000/2020/05/22/Identity-mapping/</guid>
        
        <category>Baseline</category>
        
        
      </item>
    
  </channel>
</rss>
