<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Xiaohan's Blog</title>
    <description>Do it now.</description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Wed, 24 Mar 2021 20:21:03 +0800</pubDate>
    <lastBuildDate>Wed, 24 Mar 2021 20:21:03 +0800</lastBuildDate>
    <generator>Jekyll v4.0.0</generator>
    
      <item>
        <title>跳板机连服务器打开jupyter lab</title>
        <description>&lt;p&gt;本地：&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;ssh -L 5000:host_machine_ip:5000 username@jump_machine_ip&lt;/code&gt;&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;ssh到跳板机&lt;/li&gt;
  &lt;li&gt;通过跳板机监听内网ip为host_machine_ip（管理节点）的5000端口&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;p&gt;跳板机：
opt转到host_machine_ip（管理节点）&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;host machine:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;jupyter lab --port=5000 --ip=host_machine_ip&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;jupyter_lab使用内网ip为host_machine_ip的5000端口&lt;/p&gt;
</description>
        <pubDate>Wed, 30 Dec 2020 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2020/12/30/%E8%B7%B3%E6%9D%BF%E6%9C%BA%E8%BF%9E%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%89%93%E5%BC%80jupyter-lab/</link>
        <guid isPermaLink="true">http://localhost:4000/2020/12/30/%E8%B7%B3%E6%9D%BF%E6%9C%BA%E8%BF%9E%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%89%93%E5%BC%80jupyter-lab/</guid>
        
        <category>Configurations</category>
        
        
      </item>
    
      <item>
        <title>Linux bash命令行提示符配置</title>
        <description>&lt;h4 id=&quot;bash配置文件&quot;&gt;bash配置文件&lt;/h4&gt;

&lt;p&gt;系统级的设置（default）：&lt;/p&gt;

&lt;p&gt;存储在’/etc/profile’、‘/etc/bashrc’及目录’/etc/profile.d’下的文件中&lt;/p&gt;

&lt;p&gt;用户级别的设置，不需要root权限：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;.bash_history ：以前输入的命令&lt;/li&gt;
  &lt;li&gt;.bash_logout ：退出 shell 时，要执行的命令&lt;/li&gt;
  &lt;li&gt;.bash_profile：登入 shell 时，要执行的命令&lt;/li&gt;
  &lt;li&gt;.bashrc：每次打开新的 shell 时，要执行的命令&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;当系统级与用户级的设置发生冲突时，将采用用户的设置。&lt;/p&gt;

&lt;h4 id=&quot;提示符prompt&quot;&gt;提示符prompt&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;在默认设置下，提示符将显示用户名、主机名、当前所在目录&lt;/li&gt;
  &lt;li&gt;最后一个字符可以标识普通用户($)或root(#)&lt;/li&gt;
  &lt;li&gt;通过 $PS1, $PS2 变量来设置提示符: 
 1) $PS1: 第一行出现的提示符
 2) $PS2: 在多行内输入一个命令时，换行后，出现的提示符&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;我的配置&quot;&gt;我的配置&lt;/h4&gt;

&lt;p&gt;在.bashrc最后添加&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;export PS1='\[\e[35m\]#\[\e[0m\] \[\e[36m\]\u\[\e[0m\] @ \[\e[32m\]\h\[\e[0m\] in \[\e[33m\]\w\[\e[0m\] \n\[\e[31m\]$ \[\e[0m\]'
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;reference&quot;&gt;Reference&lt;/h4&gt;
&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/u010003835/article/details/52705371&quot;&gt;Linux命令行提示符配置&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Wed, 30 Dec 2020 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2020/12/30/Linux%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%8F%90%E7%A4%BA%E7%AC%A6%E9%85%8D%E7%BD%AE/</link>
        <guid isPermaLink="true">http://localhost:4000/2020/12/30/Linux%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%8F%90%E7%A4%BA%E7%AC%A6%E9%85%8D%E7%BD%AE/</guid>
        
        <category>Configurations</category>
        
        
      </item>
    
      <item>
        <title>Jupyter lab中使用anoconda环境</title>
        <description>&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/Cactus_mao/article/details/107673655&quot;&gt;在jupyter lab中如何进入python虚拟环境&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Thu, 15 Oct 2020 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2020/10/15/Jupyterlab%E4%B8%AD%E4%BD%BF%E7%94%A8anaconda%E7%8E%AF%E5%A2%83/</link>
        <guid isPermaLink="true">http://localhost:4000/2020/10/15/Jupyterlab%E4%B8%AD%E4%BD%BF%E7%94%A8anaconda%E7%8E%AF%E5%A2%83/</guid>
        
        <category>Configurations</category>
        
        
      </item>
    
      <item>
        <title>安装tmux</title>
        <description>&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/william_munch/article/details/95764667&quot;&gt;非root用户源码安装Tmux&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://squidszyd.github.io/%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/zsh/2017/08/28/zsh.html&quot;&gt;安装ncurses&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://louiszhai.github.io/2017/09/30/tmux/&quot;&gt;tmux配置及使用&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/Xiaohan-Wang/Backup/blob/master/.tmux.conf&quot;&gt;my config&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Thu, 03 Sep 2020 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2020/09/03/%E5%AE%89%E8%A3%85tmux/</link>
        <guid isPermaLink="true">http://localhost:4000/2020/09/03/%E5%AE%89%E8%A3%85tmux/</guid>
        
        <category>Configurations</category>
        
        
      </item>
    
      <item>
        <title>安装anaconda</title>
        <description>&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.jianshu.com/p/edaa744ea47d&quot;&gt;anaconda安装与使用&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

</description>
        <pubDate>Thu, 03 Sep 2020 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2020/09/03/%E5%AE%89%E8%A3%85anaconda/</link>
        <guid isPermaLink="true">http://localhost:4000/2020/09/03/%E5%AE%89%E8%A3%85anaconda/</guid>
        
        <category>Configurations</category>
        
        
      </item>
    
      <item>
        <title>安装Oh My Zsh</title>
        <description>&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://squidszyd.github.io/%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/zsh/2017/08/28/zsh.html&quot;&gt;解决ncurses问题&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;解压 ncurses tar.gz 文件
    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;nb&quot;&gt;mkdir &lt;/span&gt;ncurses &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;tar&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-zxf&lt;/span&gt; ncurses-6.2.tar.gz &lt;span class=&quot;nt&quot;&gt;-C&lt;/span&gt; ncurses &lt;span class=&quot;nt&quot;&gt;--strip-components&lt;/span&gt; 1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://harttle.land/2016/10/25/install-oh-my-zsh-locally.html&quot;&gt;没有root权限zsh&amp;amp;oh-my-zsh安装&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://jyzhangchn.github.io/oh-my-zsh.html&quot;&gt;配置oh-my-zsh主题&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/Xiaohan-Wang/Backup/blob/master/xh-ys.zsh-theme&quot;&gt;my theme&lt;/a&gt; - modified from theme ys&lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Thu, 03 Sep 2020 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2020/09/03/%E5%AE%89%E8%A3%85oh-my-zsh/</link>
        <guid isPermaLink="true">http://localhost:4000/2020/09/03/%E5%AE%89%E8%A3%85oh-my-zsh/</guid>
        
        <category>Configurations</category>
        
        
      </item>
    
      <item>
        <title>在SLURM节点上启动Jupyter Notebook</title>
        <description>&lt;p&gt;原载于 &lt;a href=&quot;https://zhuanlan.zhihu.com/p/65130699&quot;&gt;分享脚本远程登陆 Jupyter Notebook&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&quot;服务器端&quot;&gt;服务器端&lt;/h4&gt;
&lt;h5 id=&quot;jupytergpush脚本&quot;&gt;jupyterGPU.sh脚本&lt;/h5&gt;
&lt;div class=&quot;language-zsh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#!/bin/bash&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#SBATCH --partition compsci-gpu&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#SBATCH --gres=gpu:2&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#SBATCH --time 100:00:00&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#SBATCH --job-name jupyterGPU&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# get tunneling info&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;port&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;shuf&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-i8000-9999&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-n1&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;node&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;hostname&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-s&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;user&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;whoami&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;cluster&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;hostname&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; | &lt;span class=&quot;nb&quot;&gt;awk&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-F&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;.&quot;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'{print $2}'&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# 在这里添加你的服务器地址&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;clusterurl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;xxx&quot;&lt;/span&gt;

&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;PATH&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$PATH&lt;/span&gt;:~/.local/bin

&lt;span class=&quot;c&quot;&gt;# print tunneling instructions jupyter-log&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-e&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;
MacOS or linux terminal command to create your ssh tunnel:
ssh -N -L &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;port&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;node&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;port&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;user&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;clusterurl&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;

 Here is the MobaXterm info:

 Forwarded port:same as remote port
 Remote server: &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;node&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;
 Remote port: &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;port&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;
 SSH server: &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;cluster&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;clusterurl&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;
 SSH login: &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$user&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;
 SSH port: 22

 Use a Browser on your local machine to go to:
 localhost:&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;port&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt; (prefix w/ https:// if using password)

 or copy the URL from below and put there localhost after http:// so it would be something like:
 http://localhost:9499/?token=86c93ba16aaead7529a5da0e5e5a46be7ad8cfea35b2d49f
 &quot;&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# load modules or conda environments here&lt;/span&gt;
jupyter notebook &lt;span class=&quot;nt&quot;&gt;--no-browser&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--port&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;port&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--ip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;node&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h5 id=&quot;提交jupytergpush脚本&quot;&gt;提交jupyterGPU.sh脚本&lt;/h5&gt;

&lt;div class=&quot;language-console highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;gp&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;sbatch jupyterGPU.sh
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h5 id=&quot;查看端口信息浏览器信息&quot;&gt;查看端口信息/浏览器信息&lt;/h5&gt;
&lt;div class=&quot;language-console highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;gp&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;cat &lt;/span&gt;slurm.output
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;本地&quot;&gt;本地&lt;/h4&gt;
&lt;h5 id=&quot;监听对应端口&quot;&gt;监听对应端口&lt;/h5&gt;
&lt;div class=&quot;language-console highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;gp&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;ssh &lt;span class=&quot;nt&quot;&gt;-N&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-L&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;port&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;:&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;node&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;:&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;port&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;user&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;@&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;clusterurl&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h5 id=&quot;浏览器打开jupyter-notebook&quot;&gt;浏览器打开jupyter notebook&lt;/h5&gt;
&lt;p&gt;前往&lt;code class=&quot;highlighter-rouge&quot;&gt;http://localhost:${port}&lt;/code&gt;&lt;/p&gt;

</description>
        <pubDate>Thu, 16 Jul 2020 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2020/07/16/%E5%9C%A8slurm%E4%B8%8A%E4%BD%BF%E7%94%A8jupyter-notebook/</link>
        <guid isPermaLink="true">http://localhost:4000/2020/07/16/%E5%9C%A8slurm%E4%B8%8A%E4%BD%BF%E7%94%A8jupyter-notebook/</guid>
        
        <category>Configurations</category>
        
        
      </item>
    
      <item>
        <title>Context Encoders:_Feature Learning by Inpainting</title>
        <description>&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1604.07379.pdf&quot;&gt;Paper link&lt;/a&gt; and &lt;a href=&quot;http://people.eecs.berkeley.edu/~pathak/context_encoder/&quot;&gt;website&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&quot;take-away-message&quot;&gt;Take away message&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;Image inpainting:
    &lt;ul&gt;
      &lt;li&gt;to fill in large missing areas of the image, it can’t get “hints” from nearby pixels&lt;/li&gt;
      &lt;li&gt;a model needs to both understand the content of an image, as well as produce a plausible hypothesis for the missing parts&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;a standard pixel-wise reconstruction loss&lt;/strong&gt;: only the reconstruction loss produces blurry results&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;an adversarial loss&lt;/strong&gt;: adding the adversarial loss results in much sharper predictions&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;model&quot;&gt;Model&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;Encoder-decoder pipeline:
    &lt;ul&gt;
      &lt;li&gt;encoder: produces a latent feature representation of that image&lt;/li&gt;
      &lt;li&gt;decoder: takes this feature representation and produces the missing image content
        &lt;ul&gt;
          &lt;li&gt;a series of five up-convolutional layers (upsampling followed by convolution)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;channel-wise fully-connected layer&lt;/strong&gt;: connect the encoder and the decoder
        &lt;ul&gt;
          &lt;li&gt;directly propagate information from one corner of the feature map to another corner (so that we can better capture global semantic information)&lt;/li&gt;
          &lt;li&gt;essentially a fully-connected layer with groups: only propagates information within feature maps, but it has no parameters connecting different feature maps&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Loss function:
    &lt;ul&gt;
      &lt;li&gt;reconstruction (L2) loss: 
  &lt;img src=&quot;/img/15942152334674.jpg&quot; width=&quot;50%&quot; height=&quot;100%&quot; /&gt;
        &lt;ul&gt;
          &lt;li&gt;capturing the overall structure of the missing region and coherence with regards to its context, but prefer a blurry solution (because the expectation of all possible values minimizes the mean squared pixel-wise error)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;adversarial loss: 
  &lt;img src=&quot;/img/15942164552075.jpg&quot; width=&quot;55%&quot; height=&quot;100%&quot; /&gt;
        &lt;ul&gt;
          &lt;li&gt;tries to make prediction look real, and has the effect of picking a particular mode from the distribution&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Region masks
 &lt;img src=&quot;/img/15942173051541.jpg&quot; width=&quot;60%&quot; height=&quot;100%&quot; /&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;central region&lt;/li&gt;
      &lt;li&gt;random block&lt;/li&gt;
      &lt;li&gt;random region (recommended)&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;Random block and random region produce a similarly general feature, while significantly outperforming the central region features.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;experiments&quot;&gt;Experiments&lt;/h4&gt;
&lt;h5 id=&quot;implementation-detail&quot;&gt;Implementation detail&lt;/h5&gt;
&lt;p&gt;Pool-free encoders: replacing all pooling layers with convolutions of the same kernel size and stride. (Intuitively, there is no reason to use pooling for reconstruction based networks.)&lt;/p&gt;

&lt;h5 id=&quot;evaluation&quot;&gt;Evaluation&lt;/h5&gt;
&lt;ol&gt;
  &lt;li&gt;Semantic Inpainting
&lt;img src=&quot;/img/15942140401143.jpg&quot; width=&quot;90%&quot; height=&quot;100%&quot; /&gt;
    &lt;ul&gt;
      &lt;li&gt;The encoder and discriminator architecture is similar to that of discriminator in [1], and decoder is similar to generator in [1].&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Feature Learning
 &lt;img src=&quot;/img/15942140603053.jpg&quot; width=&quot;90%&quot; height=&quot;100%&quot; /&gt;
    &lt;ul&gt;
      &lt;li&gt;For consistency with prior work, this paper use AlexNet as its encoder in this part.&lt;/li&gt;
      &lt;li&gt;The authors did not manage to make the adversarial loss converge with AlexNet, so they used just the reconstruction loss.&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;img src=&quot;/img/15942180841172.jpg&quot; alt=&quot;-w892&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;further-reference&quot;&gt;Further reference&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;A. Radford, L. Metz, and S. Chintala. Unsupervised representation learning with deep convolutional generative adversarial networks. ICLR, 2016.&lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Tue, 07 Jul 2020 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2020/07/07/Context-Encoders-Feature-Learning-by-Inpainting/</link>
        <guid isPermaLink="true">http://localhost:4000/2020/07/07/Context-Encoders-Feature-Learning-by-Inpainting/</guid>
        
        <category>Self-supervision</category>
        
        
      </item>
    
      <item>
        <title>Self-supervised feature learning 综述</title>
        <description>&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1902.06162.pdf&quot;&gt;Paper link&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&quot;self-supervised-feature-learning&quot;&gt;self-supervised feature learning&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;learn visual features from large-scale unlabeled images or videos without using any human annotations&lt;/li&gt;
  &lt;li&gt;a subset of unsupervised learning methods&lt;/li&gt;
  &lt;li&gt;pretext task: the supervisory signal is generated from the data itself by leveraging its structure&lt;/li&gt;
  &lt;li&gt;visual features of images or videos need to be captured by ConvNets to solve the pretext tasks&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;作用&quot;&gt;作用&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;作为pretext task获得pre-trained model
    &lt;ul&gt;
      &lt;li&gt;提供一个好的起始点，加速收敛&lt;/li&gt;
      &lt;li&gt;已经学习到hierarchy features，即使downstream task的数据集很小，也不会过拟合太严重&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;作为auxiliary task来添加regularization&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;分类&quot;&gt;分类&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;/img/15932024508723.jpg&quot; alt=&quot;-w1112&quot; /&gt;&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Information recovery: 先抹除图片的一部分信息，然后让网络学习恢复这些信息
    &lt;ul&gt;
      &lt;li&gt;generation based:
        &lt;ul&gt;
          &lt;li&gt;&lt;strong&gt;image generation&lt;/strong&gt;: help the network to capture the real distribution of the real data and generate realists data&lt;/li&gt;
          &lt;li&gt;&lt;strong&gt;color recovery&lt;/strong&gt;: network need to recognize objects and to group pixels of the same part together&lt;/li&gt;
          &lt;li&gt;&lt;strong&gt;inpainting&lt;/strong&gt;: networks are required to learn the common knowledge including the color and structure of the common objects&lt;/li&gt;
          &lt;li&gt;&lt;strong&gt;super resolution&lt;/strong&gt;: learn the semantic features of images&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;context based:
        &lt;ul&gt;
          &lt;li&gt;&lt;strong&gt;Context Similarity (contrasting)&lt;/strong&gt;: learn the invariance within one class and the variance among different classes
            &lt;ul&gt;
              &lt;li&gt;contrasting: train networks to maximum agreement of different views of same scene while minimizing agreement of views from different scenes&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;&lt;strong&gt;Spatial Context Structure&lt;/strong&gt;：learn spatial context information such as the shape of the objects and the relative positions of different parts of an object&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Hard-code program
    &lt;ul&gt;
      &lt;li&gt;This type of methods generally has two steps:
        &lt;ul&gt;
          &lt;li&gt;label generation by employing hard-code programs on images or videos to obtain labels,&lt;/li&gt;
          &lt;li&gt;train ConvNets with the generated labels.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;distill knowledge from hard-code detector&lt;/li&gt;
      &lt;li&gt;one drawback is that the semantic labels generated by hard-code detector usually are very noisy which need to specifically cope with.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Game Engines
    &lt;ul&gt;
      &lt;li&gt;game engines are able to render realistic images and provide accurate pixel-level labels&lt;/li&gt;
      &lt;li&gt;one problem is the domain gap between synthetic and real-world images&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;performance&quot;&gt;Performance&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;/img/15932060535480.jpg&quot; alt=&quot;-w913&quot; /&gt;
The performance of self-supervised methods are comparable to the supervised methods on some downstream tasks, especially for the object detection and semantic segmentation tasks.&lt;/p&gt;

</description>
        <pubDate>Fri, 26 Jun 2020 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2020/06/26/self-supervised-feature-learning/</link>
        <guid isPermaLink="true">http://localhost:4000/2020/06/26/self-supervised-feature-learning/</guid>
        
        <category>Self-supervision</category>
        
        
      </item>
    
      <item>
        <title>Distilling the Knowledge in a Neural Network</title>
        <description>&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1503.02531.pdf&quot;&gt;Paper link&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&quot;take-away-message&quot;&gt;Take away message&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;transfer the knowledge from the cumbersome model (used in training stage) to a small model (suitable for deployment)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;“knowledge”: a learned mapping from input vectors to output vectors&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;use the class probabilities produced by the cumbersome model as “soft targets” for training the small model.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;small probabilities in the soft targets define a rich similarity structure over the data, but it has very little influence on the cross-entropy cost function during the transfer stage because the probabilities are so close to zero&lt;/strong&gt;.
    &lt;ul&gt;
      &lt;li&gt;use “distillation” to raise the temperature of the final softmax until the cumbersome model produces a suitably soft set of targets.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;adding a small term to the objective function that encourages the small model to &lt;strong&gt;predict the true targets as well as matching the soft targets provided by the cumbersome model&lt;/strong&gt; works pretty well.&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;model&quot;&gt;Model&lt;/h4&gt;
&lt;h5 id=&quot;整体思路&quot;&gt;整体思路：&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;想要transfer的knowledge是从input到output的映射。也就是说，对于相同的input，希望cumbersome model和small model能生成相同的output (soft label)&lt;/li&gt;
  &lt;li&gt;用cumbersome model和small model产生的soft label做cross entropy loss
    &lt;ul&gt;
      &lt;li&gt;问题：除了hard target对应的概率，其它负标签的概率其实也提供了大量的信息。比如说一张2的图片，对应3的soft label是1e-6，而7的soft label是1e-9，说明这张图片除2之外，更像3而不像7。但是，如果使用传统的softmax层 (T=1)，我们很难有效利用这些信息，因为这些负标签的soft label太小了，基本不能影响cross entropy loss的结果&lt;/li&gt;
      &lt;li&gt;为了能利用负标签对应概率所提供的信息，使用distillation，通过增大T来产生softer probability distribution，此时正负标签对应的soft label差距将被缩小，因此负标签的soft label也能影响最终的cross entropy loss&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;知识蒸馏&quot;&gt;知识蒸馏&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;带温度T的softmax表达式：&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;q_{i}=\frac{\exp \left(z_{i}/T\right)}{\sum_{j} \exp \left(z_{j}/T \right)}&lt;/script&gt;
  &lt;/li&gt;
  &lt;li&gt;温度T的影响&lt;br /&gt;
  &lt;img src=&quot;/img/15928689216135.jpg&quot; width=&quot;70%&quot; height=&quot;100%&quot; /&gt;
    &lt;ul&gt;
      &lt;li&gt;原始的softmax函数是 $T=1$ 时的特例&lt;/li&gt;
      &lt;li&gt;温度越高，softmax后各个值z的分布就越平均，原本较小的soft label此时相对增大，对最终cross entropy loss的影响增大，也就提高了对这些原本soft label较小的负标签的关注程度&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;如何选择温度T
    &lt;ul&gt;
      &lt;li&gt;不是所有的负标签对应的soft label都是有效的：这些soft label本身是由Teacher-Net (cumbersome model) 训练得到的，因此结果一定存在noise，而且soft label越小，noise的影响越大&lt;/li&gt;
      &lt;li&gt;温度T决定了对负标签的关注程度
        &lt;ul&gt;
          &lt;li&gt;从有部分信息量的负标签中学习 –&amp;gt; 温度要高一些&lt;/li&gt;
          &lt;li&gt;防止受负标签中噪声的影响 –&amp;gt;温度要低一些&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;知识蒸馏方法&quot;&gt;知识蒸馏方法&lt;/h5&gt;
&lt;p&gt;&lt;img src=&quot;/img/15928705010652.jpg&quot; width=&quot;70%&quot; height=&quot;100%&quot; /&gt;&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;训练Teacher model&lt;/li&gt;
  &lt;li&gt;对Teacher model蒸馏，得到student distilled model
    &lt;ul&gt;
      &lt;li&gt;soft prediction loss：Teacher model和 Student model在相同温度T下产生的soft label的cross entropy loss&lt;/li&gt;
      &lt;li&gt;hard prediction loss：Student model在T=1时和groundtruth的cross entropy loss&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;note&quot;&gt;Note&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;the magnitudes of the gradients produced by the soft targets scale as $\frac{1}{T^2}$, so it is important to multiply them by $T^2$ when using both hard and soft targets&lt;/li&gt;
  &lt;li&gt;matching logits is a special case of distillation&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;参考资料&quot;&gt;参考资料&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/102038521&quot;&gt;知识蒸馏&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/61944055&quot;&gt;交叉熵与KL散度&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Sun, 21 Jun 2020 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2020/06/21/Distilling-the-Knowledge-in-a-Neural-Network/</link>
        <guid isPermaLink="true">http://localhost:4000/2020/06/21/Distilling-the-Knowledge-in-a-Neural-Network/</guid>
        
        <category>Knowledge Distillation</category>
        
        
      </item>
    
  </channel>
</rss>
