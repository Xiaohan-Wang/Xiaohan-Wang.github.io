---
layout:     post
title: DeepLab v1
subtitle:   ICLR 2015 (Arxiv 2014)
date:       2020-5-7
author:     Xiaohan
header-img: img/ice.jpg
catalog: true
tags:
    - Semantic Segmentation
---

[Paper link](https://arxiv.org/pdf/1412.7062.pdf)

[//]: #(<img src="" width="100%" height="100%">)

#### Take away message
1. two technical hurdles in the application of DCNNs to image labeling tasks: signal downsampling, and spatial ‘insensitivity’ (invariance).
2. signal downsampling: reduction of signal resolution incurred by the repeated max-pooling -> employ the atrous algorithm (就是dilated convolution)
3. spatial insensitivity: object-centric decisions from a classifier requires invariance to spatial transformations, inherently limiting the spatial accuracy of the DCNN model -> capture fine details by employing a fully-connected Conditional Random Field (CRF) + multi-scale prediction

#### Model
1. 修改自VGG-16
2. decouple the DCNN and CRF training stages, assuming the DCNN unary terms are fixed when setting the CRF parameters  

![-w724](/img/15888811976149.jpg)

##### efficient feature extraction: atrous algorithm + reducing model
1. To compute scores more densely at target stride of 8 pixels:  
    <img src="/img/15888799732428.jpg" width="70%" height="100%">
    1. convert the fully-connected layers of VGG-16 into convolutional ones and run the network in a convolutional fashion on the image at its original resolution
    2. instead of subsampling after the last two max-pooling layers in the network, use the convolutional filters with an input stride of 2 or 4 pixels, respectively.

2. After converting the network to a fully convolutional one, the first fully connected layer has 4,096 filters of large 7×7 spatial size and becomes the computational bottleneck.
    1. Use filters with 4×4 (or 3×3) spatial size but with the same receptive fields.
    2. reducing the number of channels at the fully connected layers from 4,096 down to 1,024.

##### detail boundary recovery: fully-connected CRF + multi-scale prediction
1. fully-connected CRF 
    ![-w723](/img/15888811265917.jpg)
    
    1. Energy function:  
        <img src="/img/15888817215422.jpg" width="40%" height="100%">
    2. first term:  
        <img src="/img/15888818741237.jpg" width="25%" height="100%">
    3. second term:  
        <img src="/img/15888819146749.jpg" width="55%" height="100%">  
        <img src="/img/15888820310003.jpg" width="25%" height="100%">  
        the kernels are:  
        <img src="/img/15888821802918.jpg" width="55%" height="100%">  
        The first kernel forces pixels with similar color and position to have similar labels, while the second kernel only considers spatial proximity when enforcing smoothness.

1. multi-scale prediction
    attach to the input image and the output of each of the first four max pooling layers a two-layer MLP (first layer: 128 3x3 convolutional filters, second layer: 128 1x1 convolutional fil- ters) whose feature map is concatenated to the main network’s last layer feature map. The aggregate feature map fed into the softmax layer is thus enhanced by 5 * 128 = 640 channels. 

#### Result
![-w794](/img/15888828891435.jpg)
![-w739](/img/15888829216375.jpg)
![-w702](/img/15888829687129.jpg)
![-w725](/img/15888830739237.jpg)


#### Further reference
1. [部分翻译](http://hellodfan.com/2018/01/22/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E8%AE%BA%E6%96%87-DeepLab%E7%B3%BB%E5%88%97/)
2. Krahenbuhl, P. and Koltun, V. Efficient inference in fully connected crfs with gaussian edge poten- tials. In NIPS, 2011.