---
layout:     post
title: ADVENT:Adversarial Entropy Minimization for Domain Adaptation in Semantic Segmentation
subtitle:   CVPR 2019 
date:       2020-3-21
author:     Xiaohan
header-img: img/ice.jpg
catalog: true
tags:
    - Domain Adaptation
---

[Paper link](https://arxiv.org/pdf/1811.12833.pdf) and [code](https://github.com/valeoai/ADVENT)

#### Take away message
1. 观察到source domain prediction是over-confident / low entropy，而target domain prediction是under-confident / high entropy
2. direct entropy minimization
3. structure adaptation: adversarial learning 

#### Model
![-w930](/img/15850310997747.jpg)

class ratio prior:  
Entropy minimization can get biased towards some easy classes. Therefore, sometimes it is beneficial to guide the learning with some prior. 此处根据class ratio prior设计了另一个Loss来guide learning.

1. entropy map and $L_{ent}$  
<img src="/img/15850758404417.jpg" width="40%" height="40%">  
<img src="/img/15850759324138.jpg" width="25%" height="40%">  
a soft-assignment version of the pseudo-label cross-entropy loss   
1. Adversarial learning loss



#### Result
1. In general, AdvEnt works better than MinEnt. By combining results of the two models MinEnt and AdvEnt, we observe a decent boost in performance, compared to results of single models. 
![-w923](/img/15850315105452.jpg)


1. oracle performance (trained on source and target)
<img src="/img/15850315456104.jpg" width="40%" height="40%">

#### Tricks
1. Training on specific entropy ranges.
2. Using class-ratio prior.

#### Insight
1. 找source domain结果/中间feature map具备、而target domain不具备的性质，用adversarial learning (e.g. cross entropy)


