---
layout:     post
title: slurm使用基础
subtitle:   
date:       2020-6-5
author:     Xiaohan
header-img: img/ice.jpg
catalog: true
tags:
    - Slurm
---

[//]: #(<img src="" width="100%" height="100%">)

SLURM：开源作业调度系统

#### 提交作业
##### 提交方式
Slurm提交作业有3种模式，分别为交互模式，批处理模式，分配模式。这三种方式**只是用户使用方式的区别，而在管理，调度，记账时同等对待**
1. 交互模式(srun)：交互式作业提交，提交命令后，等待作业执行完成之后返回命令行窗口。
2. 批处理模式(sbatch)：用户编写作业脚本，指定资源需求约束，提交后台执行作业。
3. 分配模式(salloc)：结点资源抢占命令。该命令支持用户在提交作业前，抢占所需计算资源。

##### 运行参数
以下参数适用于所有作业提交命令(srun, sbatch, salloc)。**sbatch时可以通过脚本提交或命令行提交**。

常用：

<style>
table th:first-of-type {
    width: 8%;
}
table th:nth-of-type(2) {
    width: 28%;
}
table th:nth-of-type(3) {
    width: 25%;
}
table th:nth-of-type(4) {
    width: 39%;
}
</style>

| 参数 | 简写 | 作用 | 备注 |
| --- | --- | --- | --- |
| -p | --partition | 指定队列资源| |
||--gres=gpu:\<number> | 每个节点的GPU数|gres是generic resource|
| -J | --job-name | 指定作业名称 |  |
|-w | –nodelist=\<host1,host2,...>|在指定的节点上运行||

其他：

| 参数 | 简写 | 作用 | 备注 |
| --- | --- | --- | --- |
|-N| --nodes=\<number\> |指定节点数量| 是节点数，不是CPU核数，实际分配的是节点数×每节点CPU核数|
|-n | --ntasks=\<number\> |  运行\<number\>个任务 | 默认为每个节点一个任务，注意是所需总CPU核数|
||--ntasks-per-node=\<ntasks>|每个节点运行\<ntasks>个任务|需与-n=\<number>配合|
||–ntasks-per-core=\<ntasks>|每颗CPU核运行\<ntasks>个任务|需与-n=\<number>配合，并自动绑定\<ntasks>个任务到每个CPU核|




#### 查看信息
##### 队列
1. sinfo：显示队列中各个节点的状态（idle, mix, alloc, drain）
    * idle，表示节点处于空闲状态
    * mix，节点具有分配CPU的作业，而其他的CPU状态是IDLE，新提交的作业继续运行
    * alloc，节点所有CPU都被占用，新提交的作业将排队
    * drain，出现这个状态时，不影响正在运行的作业，但是不接受新的作业调度，可以使用命令sinfo –R打印节点不正常的状态产生原因
    * down 故障节点不可用
2. scontrol show partition \<partition name>：显示队列详细信息

#### 作业
1. squeue：显示排队和运行中的作业（可以设置参数限制显示范围，e.g. -u显示特定user的作业）
2. scontrol show job \<job id>：实时作业详细信息

#### 节点
1. scontrol show node \<node name>：显示节点状态
    * CfgTRES: 该节点的总资源（TRES表示Trackable Resource）
        * CfgTRES=cpu=32,mem=257828M,billing=32,gres/gpu=8
    * AllocTRES: 已经分配的资源
        * AllocTRES=cpu=4,mem=8800M,gres/gpu=2：已经占用 了 4 个 CPU 核心，8800 MB 内存和 2 块 GPU 卡

#### 简单使用方法
1. sinfo -> 查看总体GPU使用情况
2. scontrol show node \<node name> -> 查看具体节点GPU剩余情况
3. sbatch -w \<node name> --gres=gpu:\<number> train.sh -> 在相应节点上request对应的GPU资源
4. scontrol show job \<jobid> -> 查看任务详细信息

在申请相应资源后，任务只能**获取到**对应部分资源。比如说，无论节点总体的GPU使用情况如何 (e.g. 一共8个GPU，已占用3个)，若--gres=gpu:4 (申请了4个GPU)，那么程序的CUDA_VISIBLE_DEVICES=0,1,2,3



#### 参考资料
1. [SLURM使用基础教程](https://www.hpccube.com/wiki/index.php/SLURM%E4%BD%BF%E7%94%A8%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B#.E6.96.87.E6.A1.A3.E6.A6.82.E8.BF.B0)
2. [Slurm作业调度系统使用指南](http://hmli.ustc.edu.cn/doc/userguide/slurm-userguide.pdf)