---
layout:     post
title:  Self-supervised feature learning 综述
subtitle:   TPAMI 2020
date:       2020-6-26
author:     Xiaohan
header-img: img/ice.jpg
catalog: true
tags:
    - Self-supervision
---

[Paper link](https://arxiv.org/pdf/1902.06162.pdf) 

[//]: #(<img src="" width="100%" height="100%">)


#### self-supervised feature learning
* learn visual features from large-scale unlabeled images or videos without using any human annotations
* a subset of unsupervised learning methods
* pretext task: the supervisory signal is generated from the data itself by leveraging its structure
* visual features of images or videos need to be captured by ConvNets to solve the pretext tasks

#### 作用
1. 作为pretext task获得pre-trained model
    * 提供一个好的起始点，加速收敛
    * 已经学习到hierarchy features，即使downstream task的数据集很小，也不会过拟合太严重
2. 作为auxiliary task来添加regularization

#### 分类
![-w1112](/img/15932024508723.jpg)
1. Information recovery: 先抹除图片的一部分信息，然后让网络学习恢复这些信息
    * generation based:
        * **image generation**: help the network to capture the real distribution of the real data and generate realists data
        * **color recovery**: network need to recognize objects and to group pixels of the same part together
        * **inpainting**: networks are required to learn the common knowledge including the color and structure of the common objects
        * **super resolution**: learn the semantic features of images
    * context based: 
        * **Context Similarity (contrasting)**: learn the invariance within one class and the variance among different classes 
            * contrasting: train networks to maximum agreement of different views of same scene while minimizing agreement of views from different scenes 
        * **Spatial Context Structure**：learn spatial context information such as the shape of the objects and the relative positions of different parts of an object
2. Hard-code program
    * This type of methods generally has two steps: 
        * label generation by employing hard-code programs on images or videos to obtain labels, 
        * train ConvNets with the generated labels.
    * distill knowledge from hard-code detector
    * one drawback is that the semantic labels generated by hard-code detector usually are very noisy which need to specifically cope with.
3. Game Engines
    * game engines are able to render realistic images and provide accurate pixel-level labels
    * one problem is the domain gap between synthetic and real-world images

#### Performance
![-w913](/img/15932060535480.jpg)
The performance of self-supervised methods are comparable to the supervised methods on some downstream tasks, especially for the object detection and semantic segmentation tasks.



